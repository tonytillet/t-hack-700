# ğŸš€ Guide de dÃ©marrage rapide - Pipeline Grippe

## âš¡ Lancement rapide

```bash
cd scripts

# Pipeline complÃ¨te en 3 Ã©tapes
python collect_all_data.py  # Collecte les donnÃ©es
python fuse_data.py          # Fusionne les donnÃ©es
python train_model.py        # EntraÃ®ne les modÃ¨les
```

**âš ï¸ Important** : Vous devez d'abord exÃ©cuter `collect_all_data.py` pour gÃ©nÃ©rer les donnÃ©es avant de lancer `fuse_data.py`.

## ğŸ“‹ Ce qui se passe

### 1. **Collecte** (collect_all_data.py)
   - Collecte **13 sources de donnÃ©es** :
     - Google Trends (3 sources)
     - Wikipedia (2 sources)
     - SPF - SantÃ© Publique France (4 sources)
     - Contexte : INSEE + MÃ©tÃ©o (4 sources)
   - Sauvegarde dans `data/google_trends/`, `data/wikipedia/`, `data/spf/`, `data/context/`

### 2. **Fusion** (fuse_data.py)
   - Fusionne les 13 sources de donnÃ©es
   - CrÃ©e des features avancÃ©es (lags, moyennes mobiles, z-scores)
   - Calcule l'indice **FLURISK** (indicateur de risque grippe)
   - GÃ¨re les 13 rÃ©gions franÃ§aises
   - Sauvegarde dans `data/processed/`

### 3. **EntraÃ®nement** (train_model.py)
   - EntraÃ®ne 4 modÃ¨les Random Forest (J+7, J+14, J+21, J+28)
   - GÃ©nÃ¨re les prÃ©dictions avec mÃ©triques dÃ©taillÃ©es
   - Sauvegarde modÃ¨les, mÃ©triques et importance des features
   - Sauvegarde dans `models/`

## ğŸ“ RÃ©sultats

AprÃ¨s exÃ©cution, vous trouverez:

```
data/
â”œâ”€â”€ google_trends/       â† DonnÃ©es Google Trends
â”œâ”€â”€ wikipedia/           â† DonnÃ©es Wikipedia
â”œâ”€â”€ spf/                 â† DonnÃ©es SantÃ© Publique France
â”œâ”€â”€ context/             â† DonnÃ©es INSEE + MÃ©tÃ©o
â””â”€â”€ processed/           â† Dataset fusionnÃ© avec FLURISK

models/                  â† ModÃ¨les entraÃ®nÃ©s (.pkl)
â”œâ”€â”€ rf_grippe_j7_*.pkl
â”œâ”€â”€ rf_grippe_j14_*.pkl
â”œâ”€â”€ rf_grippe_j21_*.pkl
â”œâ”€â”€ rf_grippe_j28_*.pkl
â”œâ”€â”€ config_*.json
â””â”€â”€ metrics_*.csv
```

## ğŸ“Š ExÃ©cution Ã©tape par Ã©tape

Si vous prÃ©fÃ©rez exÃ©cuter Ã©tape par Ã©tape:

```bash
cd scripts

# Ã‰tape 1: Collecte des donnÃ©es (13 sources)
python collect_all_data.py

# Ã‰tape 2: Fusion et crÃ©ation des features
python fuse_data.py

# Ã‰tape 3: EntraÃ®nement des modÃ¨les
python train_model.py
```

## ğŸ” Collecteurs individuels

Vous pouvez aussi lancer les collecteurs individuellement:

```bash
# Google Trends uniquement
python collect_google_trends.py

# Wikipedia uniquement
python collect_wikipedia.py

# SPF (SantÃ© Publique France) uniquement
python collect_spf_data.py

# Contexte (INSEE + MÃ©tÃ©o) uniquement
python collect_context_data.py
```

## ğŸ¯ FonctionnalitÃ©s avancÃ©es

### Indice FLURISK
Le script `fuse_data.py` calcule automatiquement l'indice FLURISK pour chaque rÃ©gion :
- **0-50** : Risque faible ğŸŸ¢
- **50-70** : Risque moyen ğŸŸ 
- **70-100** : Risque Ã©levÃ© ğŸ”´

### Features crÃ©Ã©es
- Lags : 1, 2, 3, 4, 8, 12 semaines
- Moyennes mobiles : 3, 4, 8 semaines
- Z-scores pour normalisation
- Ratios et interactions

### RÃ©gions gÃ©rÃ©es
13 rÃ©gions franÃ§aises :
- Ãle-de-France
- Auvergne-RhÃ´ne-Alpes
- Nouvelle-Aquitaine
- Occitanie
- Hauts-de-France
- Grand Est
- Pays de la Loire
- Bretagne
- Normandie
- Centre-Val de Loire
- Bourgogne-Franche-ComtÃ©
- Provence-Alpes-CÃ´te d'Azur
- Corse

## ğŸ› En cas de problÃ¨me

- **Erreur de collecte**: Les scripts gÃ©nÃ¨rent automatiquement des donnÃ©es simulÃ©es
- **DonnÃ©es manquantes**: VÃ©rifiez que chaque Ã©tape s'est bien terminÃ©e
- **Erreur de modÃ¨le**: VÃ©rifiez qu'il y a assez de donnÃ©es dans `data/processed/`

## ğŸ“– Documentation complÃ¨te

- **`docs/SCRIPTS.md`** - DÃ©tails sur chaque script
- **`docs/FLURISK.md`** - Explication complÃ¨te de l'indice FLURISK
- **`docs/VISUALISATION.md`** - Guide complet de `app.py` et `demo.py`

## ğŸ‘ï¸ Visualiser les rÃ©sultats

### Option 1 : Application Web Streamlit (RecommandÃ©)

```bash
streamlit run app.py
```

Ouvre une interface web interactive avec :
- ğŸ—ºï¸ Carte de France avec FLURISK par rÃ©gion
- ğŸ“‹ Top 10 prioritÃ©s des rÃ©gions Ã  risque
- ğŸ” Zoom dÃ©partement avec prÃ©dictions J+7, J+14, J+21, J+28
- ğŸ›ï¸ Simulation ROI des campagnes de vaccination
- ğŸ’¾ Export CSV

**URL** : http://localhost:8501

### Option 2 : VÃ©rification rapide en terminal

```bash
python demo.py
```

Affiche dans le terminal :
- âœ… Ã‰tat des donnÃ©es collectÃ©es
- ğŸ“Š Statistiques du dataset
- ğŸš¨ FLURISK actuel par rÃ©gion (Top 5)
- ğŸ¤– Performance des modÃ¨les (MAE, RÂ²)
- ğŸŒ Statut de l'application Streamlit

### Option 3 : Voir les fichiers directement

**FLURISK et donnÃ©es :**
- `data/processed/dataset_grippe_*.csv` - Dataset complet avec FLURISK

**MÃ©triques des modÃ¨les :**
- `models/metrics_j7_*.csv` - Performance J+7
- `models/metrics_j14_*.csv` - Performance J+14
- `models/metrics_j21_*.csv` - Performance J+21
- `models/metrics_j28_*.csv` - Performance J+28

**Importance des features :**
- `models/importance_*.csv` - Importance de FLURISK et autres variables

**PrÃ©dictions :**
- `data/processed/dataset_with_predictions_*.csv` - Dataset avec prÃ©dictions

## âœ… VÃ©rification rapide

Pour vÃ©rifier que tout fonctionne:

```bash
cd scripts
python collect_all_data.py
```

Vous devriez voir:
```
âœ… COLLECTE TERMINÃ‰E
ğŸ’¡ Prochaine Ã©tape: Fusion et traitement des donnÃ©es
```

DurÃ©e estimÃ©e: 3-5 minutes pour la pipeline complÃ¨te
