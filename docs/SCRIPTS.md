# ğŸ“Š Scripts de la pipeline de collecte de donnÃ©es

## ğŸ“ Scripts existants

### âœ… Scripts de collecte de donnÃ©es (EXISTANTS)

| Script | Fonction | Sources | Statut |
|--------|----------|---------|--------|
| **`collect_all_data.py`** | **Orchestrateur principal** | Appelle tous les collecteurs | âœ… **EXISTE** |
| `collect_google_trends.py` | Google Trends | Recherches "grippe", "vaccin", "symptÃ´mes" | âœ… Existe |
| `collect_wikipedia.py` | Wikipedia | Vues pages "Grippe" et "Vaccination" | âœ… Existe |
| `collect_spf_data.py` | SantÃ© Publique France | Urgences, sentinelles, vaccination, IAS | âœ… Existe |
| `collect_context_data.py` | DonnÃ©es contextuelles | Population INSEE, mÃ©tÃ©o | âœ… Existe |

### ğŸ”„ Scripts de traitement (EXISTANTS)

| Script | Fonction | Statut |
|--------|----------|--------|
| **`fuse_data.py`** | Fusion de toutes les sources | âœ… Existe |
| **`train_model.py`** | EntraÃ®nement Random Forest | âœ… Existe |

### ğŸ‘ï¸ Scripts de visualisation (EXISTANTS)

| Script | Fonction | Statut |
|--------|----------|--------|
| **`app.py`** | Application web Streamlit interactive | âœ… Existe |
| **`demo.py`** | Script de vÃ©rification rapide (terminal) | âœ… Existe |

### ğŸ†• Scripts crÃ©Ã©s rÃ©cemment (PAR MOI)

| Script | Fonction | Statut |
|--------|----------|--------|
| `01_clean_data.py` | Nettoyage avec URLs | ğŸ†• Nouveau |
| `02_merge_data.py` | Fusion simplifiÃ©e | ğŸ†• Nouveau |
| `03_predict.py` | PrÃ©diction simplifiÃ©e | ğŸ†• Nouveau |
| `run_pipeline.py` | Orchestrateur simple | ğŸ†• Nouveau |

---

## ğŸ¯ Script orchestrateur principal : `collect_all_data.py`

### âœ… Ce qu'il fait dÃ©jÃ 

```python
# Ã‰tape 1: Google Trends
from collect_google_trends import GoogleTrendsCollector
gt_collector = GoogleTrendsCollector()
gt_data = gt_collector.collect_all_data()

# Ã‰tape 2: Wikipedia
from collect_wikipedia import WikipediaCollector
wiki_collector = WikipediaCollector()
wiki_data = wiki_collector.collect_all_data()

# Ã‰tape 3: SPF (SantÃ© Publique France)
from collect_spf_data import SPFDataCollector
spf_collector = SPFDataCollector()
spf_data = spf_collector.collect_all_data()

# Ã‰tape 4: Contexte (INSEE + MÃ©tÃ©o)
from collect_context_data import ContextDataCollector
context_collector = ContextDataCollector()
context_data = context_collector.collect_all_data()
```

### ğŸ“Š Sources collectÃ©es (13 au total)

1. **Google Trends** (3 sources)
   - Recherches "grippe"
   - Recherches "vaccin grippe"
   - Recherches "symptÃ´mes grippe"

2. **Wikipedia** (2 sources)
   - Vues page "Grippe"
   - Vues page "Vaccination"

3. **SPF - SantÃ© Publique France** (4 sources)
   - Urgences grippe
   - Sentinelles
   - Vaccination
   - IAS (Indicateurs AvancÃ©s Sanitaires)

4. **Contexte** (2 sources)
   - Population INSEE (par rÃ©gion)
   - MÃ©tÃ©o (tempÃ©rature, humiditÃ©)

5. **Autres** (2 sources potentielles)
   - DonnÃ©es rÃ©elles Google Trends
   - DonnÃ©es rÃ©elles INSEE/MÃ©tÃ©o

---

## ğŸ”„ Pipeline complÃ¨te existante

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   COLLECTE DES DONNÃ‰ES                      â”‚
â”‚                  (collect_all_data.py)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                   â†“                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Google       â”‚   â”‚ Wikipedia    â”‚   â”‚ SPF          â”‚
â”‚ Trends       â”‚   â”‚              â”‚   â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                   â†“                   â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FUSION DES DONNÃ‰ES                        â”‚
â”‚                     (fuse_data.py)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ENTRAÃNEMENT DU MODÃˆLE                         â”‚
â”‚                  (train_model.py)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Structure des donnÃ©es

```
data/
â”œâ”€â”€ google_trends/
â”‚   â””â”€â”€ google_trends_latest.csv
â”œâ”€â”€ wikipedia/
â”‚   â””â”€â”€ wikipedia_latest.csv
â”œâ”€â”€ spf/
â”‚   â”œâ”€â”€ spf_urgences_*.csv
â”‚   â”œâ”€â”€ spf_sentinelles_*.csv
â”‚   â”œâ”€â”€ spf_vaccination_*.csv
â”‚   â””â”€â”€ spf_ias_*.csv
â”œâ”€â”€ context/
â”‚   â”œâ”€â”€ context_population_*.csv
â”‚   â””â”€â”€ context_weather_*.csv
â””â”€â”€ processed/
    â””â”€â”€ dataset_grippe_*.csv
```

---

## âš–ï¸ Comparaison : Pipeline existante vs nouvelle

| Aspect | Pipeline EXISTANTE | Pipeline NOUVELLE (crÃ©Ã©e) |
|--------|-------------------|---------------------------|
| **Collecte** | âœ… ComplÃ¨te (13 sources) | âš ï¸ SimplifiÃ©e (5 sources) |
| **Sources** | Google Trends, Wikipedia, SPF, INSEE, MÃ©tÃ©o | URLs data.gouv.fr uniquement |
| **Orchestrateur** | âœ… `collect_all_data.py` | ğŸ†• `run_pipeline.py` |
| **Fusion** | âœ… `fuse_data.py` (complet) | ğŸ†• `02_merge_data.py` (simple) |
| **ModÃ¨le** | âœ… `train_model.py` (complet) | ğŸ†• `03_predict.py` (simple) |
| **Features** | âœ… TrÃ¨s complet (lags, MA, z-scores) | âš ï¸ Basique (lags, MA) |
| **FLURISK** | âœ… CalculÃ© | âŒ Non calculÃ© |
| **DonnÃ©es rÃ©elles** | âœ… Scripts pour vraies APIs | âŒ DonnÃ©es simulÃ©es |

---

## ğŸ¯ Recommandations

### âœ… CE QUI EXISTE DÃ‰JÃ€ ET FONCTIONNE

1. **`collect_all_data.py`** - Orchestrateur complet âœ…
   - Appelle tous les collecteurs
   - GÃ¨re les erreurs
   - Affiche les statistiques

2. **`fuse_data.py`** - Fusion complÃ¨te âœ…
   - Fusionne les 13 sources
   - CrÃ©e des features avancÃ©es
   - Calcule FLURISK
   - Gestion des rÃ©gions

3. **`train_model.py`** - ModÃ¨le complet âœ…
   - Multi-horizons (J+7, J+14, J+21, J+28)
   - MÃ©triques dÃ©taillÃ©es
   - Sauvegarde des modÃ¨les

### ğŸ”§ CE QU'IL FAUT FAIRE

#### Option 1 : Utiliser la pipeline existante (RECOMMANDÃ‰) âœ…

```bash
# Ã‰tape 1: Collecter toutes les donnÃ©es
python scripts/collect_all_data.py

# Ã‰tape 2: Fusionner les donnÃ©es
python scripts/fuse_data.py

# Ã‰tape 3: EntraÃ®ner le modÃ¨le
python scripts/train_model.py
```

#### Option 2 : CrÃ©er un orchestrateur global

CrÃ©er un nouveau script `run_full_pipeline.py` qui appelle :
1. `collect_all_data.py`
2. `fuse_data.py`
3. `train_model.py`

#### Option 3 : AmÃ©liorer les collecteurs existants

- Ajouter les vraies URLs dans les collecteurs
- Utiliser `data_urls_config.json` comme configuration
- AmÃ©liorer la gestion des erreurs

---

## ğŸš¨ Points d'attention

### âš ï¸ Doublons dÃ©tectÃ©s

Vous avez maintenant **DEUX pipelines** :

1. **Pipeline EXISTANTE** (complÃ¨te, professionnelle)
   - `collect_all_data.py` â†’ `fuse_data.py` â†’ `train_model.py`
   - 13 sources de donnÃ©es
   - Features avancÃ©es
   - FLURISK calculÃ©

2. **Pipeline NOUVELLE** (simple, basique)
   - `run_pipeline.py` â†’ `01_clean_data.py` â†’ `02_merge_data.py` â†’ `03_predict.py`
   - 5 sources de donnÃ©es
   - Features basiques
   - Pas de FLURISK

### ğŸ’¡ Recommandation finale

**UTILISER LA PIPELINE EXISTANTE** et crÃ©er simplement un orchestrateur global :

```python
# run_full_pipeline.py
import subprocess

# Ã‰tape 1: Collecte
subprocess.run(['python', 'scripts/collect_all_data.py'])

# Ã‰tape 2: Fusion
subprocess.run(['python', 'scripts/fuse_data.py'])

# Ã‰tape 3: ModÃ¨le
subprocess.run(['python', 'scripts/train_model.py'])
```

---

## ğŸ“ Conclusion

âœ… **Vous avez dÃ©jÃ  une pipeline complÃ¨te et fonctionnelle !**

- `collect_all_data.py` collecte tout
- `fuse_data.py` fusionne tout
- `train_model.py` entraÃ®ne tout

**Il suffit de crÃ©er un script orchestrateur qui les appelle dans l'ordre.**

### âœ… Script orchestrateur crÃ©Ã© : `run_full_pipeline.py`

**Script qui exÃ©cute automatiquement les 3 Ã©tapes de la pipeline.**

#### Utilisation
```bash
python run_full_pipeline.py
```

#### Ce qu'il fait
1. âœ… ExÃ©cute `collect_all_data.py` (Collecte)
2. âœ… ExÃ©cute `fuse_data.py` (Fusion + FLURISK)
3. âœ… ExÃ©cute `train_model.py` (EntraÃ®nement)
4. âœ… Affiche un rÃ©sumÃ© dÃ©taillÃ© avec durÃ©es
5. âœ… GÃ¨re les erreurs et arrÃªte si une Ã©tape Ã©choue

#### Avantages
- ğŸ¯ Une seule commande pour tout
- â±ï¸ Suivi du temps d'exÃ©cution
- ğŸ“Š RÃ©sumÃ© dÃ©taillÃ© Ã  la fin
- âŒ Gestion des erreurs
- ğŸ›‘ ArrÃªt automatique en cas d'Ã©chec

---

## ğŸ‘ï¸ Scripts de Visualisation

### `app.py` - Application Web Streamlit

**Interface web interactive** pour visualiser les prÃ©dictions de grippe.

#### FonctionnalitÃ©s
- ğŸ—ºï¸ **Carte de France** avec FLURISK par rÃ©gion
- ğŸ“‹ **Top 10 prioritÃ©s** des rÃ©gions Ã  risque + export CSV
- ğŸ” **Zoom dÃ©partement** avec prÃ©dictions J+7, J+14, J+21, J+28
- ğŸ›ï¸ **Simulation ROI** des campagnes de vaccination

#### Lancement
```bash
streamlit run app.py
```
**URL** : http://localhost:8501

#### PrÃ©requis
- Dataset avec prÃ©dictions : `data/processed/dataset_with_predictions_*.csv`
- ModÃ¨les entraÃ®nÃ©s : `models/rf_grippe_*.pkl`

---

### `demo.py` - Script de VÃ©rification

**Script terminal** qui affiche un rÃ©sumÃ© du systÃ¨me.

#### Affiche
- âœ… Ã‰tat des donnÃ©es collectÃ©es
- ğŸ“Š Statistiques du dataset
- ğŸš¨ FLURISK actuel par rÃ©gion (Top 5)
- ğŸ¤– Performance des modÃ¨les (MAE, RÂ²)
- ğŸŒ Statut de l'application Streamlit
- ğŸš€ Prochaines Ã©tapes suggÃ©rÃ©es

#### Lancement
```bash
python demo.py
```

#### Utilisation
IdÃ©al pour vÃ©rifier rapidement que tout fonctionne avant une dÃ©monstration.

---

## ğŸ“– Documentation ComplÃ¨te

Pour plus de dÃ©tails sur la visualisation, consultez **`docs/VISUALISATION.md`**.
