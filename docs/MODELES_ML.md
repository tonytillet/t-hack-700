# ðŸ¤– LUMEN - ModÃ¨les Machine Learning

## ðŸ“‹ Table des MatiÃ¨res
- [Vue d'ensemble](#vue-densemble)
- [ModÃ¨le Principal](#modÃ¨le-principal)
- [Architecture du ModÃ¨le](#architecture-du-modÃ¨le)
- [HyperparamÃ¨tres](#hyperparamÃ¨tres)
- [Performance](#performance)
- [Comparaison de ModÃ¨les](#comparaison-de-modÃ¨les)
- [EntraÃ®nement](#entraÃ®nement)

---

## ðŸŽ¯ Vue d'ensemble

LUMEN utilise actuellement **UN SEUL modÃ¨le** de Machine Learning pour les prÃ©dictions :

### ModÃ¨le UtilisÃ©
- **ðŸŒ³ Random Forest Regressor** (ForÃªt AlÃ©atoire)
- **BibliothÃ¨que** : scikit-learn
- **Type** : RÃ©gression (prÃ©diction de valeurs continues)
- **Fichier** : `ml/train_random_forest.py`

### Pourquoi Random Forest ?

âœ… **Avantages** :
- **Robuste** : RÃ©sistant au sur-apprentissage
- **Performant** : Excellentes performances sans tuning intensif
- **InterprÃ©table** : Importance des features facilement analysable
- **Versatile** : GÃ¨re bien les relations non-linÃ©aires
- **Stable** : Peu sensible aux valeurs aberrantes

âŒ **InconvÃ©nients** :
- Temps d'entraÃ®nement plus long que les modÃ¨les linÃ©aires
- Taille du modÃ¨le plus importante
- Moins performant sur donnÃ©es trÃ¨s volumineuses (>1M lignes)

---

## ðŸŒ³ ModÃ¨le Principal : Random Forest Regressor

### Description

Le **Random Forest** est un ensemble de **300 arbres de dÃ©cision** qui votent pour faire une prÃ©diction. Chaque arbre est entraÃ®nÃ© sur un sous-ensemble alÃ©atoire des donnÃ©es.

### Architecture

```
ðŸŒ³ Random Forest Regressor
â”œâ”€â”€ 300 arbres de dÃ©cision
â”œâ”€â”€ Profondeur maximale: 10 niveaux
â”œâ”€â”€ Ã‰chantillonnage: Bootstrap (avec remplacement)
â”œâ”€â”€ Features par split: sqrt(n_features)
â””â”€â”€ PrÃ©diction finale: Moyenne des 300 arbres
```

### HyperparamÃ¨tres Actuels

```python
RandomForestRegressor(
    n_estimators=300,      # Nombre d'arbres
    max_depth=10,          # Profondeur maximale
    random_state=42,       # ReproductibilitÃ©
    n_jobs=-1              # Utilise tous les CPU
)
```

| ParamÃ¨tre | Valeur | Description |
|-----------|--------|-------------|
| **n_estimators** | 300 | Nombre d'arbres dans la forÃªt |
| **max_depth** | 10 | Profondeur maximale de chaque arbre |
| **random_state** | 42 | Graine alÃ©atoire pour reproductibilitÃ© |
| **n_jobs** | -1 | ParallÃ©lisation (tous les CPU) |
| **min_samples_split** | 2 (dÃ©faut) | Minimum d'Ã©chantillons pour split |
| **min_samples_leaf** | 1 (dÃ©faut) | Minimum d'Ã©chantillons par feuille |
| **max_features** | auto (dÃ©faut) | Features considÃ©rÃ©es par split |

---

## ðŸ“Š Performance

### MÃ©triques Actuelles

D'aprÃ¨s les mÃ©moires du projet :

| MÃ©trique | Valeur | Description |
|----------|--------|-------------|
| **RÂ² Score** | 0.971 | 97.1% de variance expliquÃ©e |
| **MAE** | 5.08 | Erreur absolue moyenne |
| **RMSE** | 8.23 | Erreur quadratique moyenne |

**Note** : Ces mÃ©triques peuvent varier selon la version du dataset.

### InterprÃ©tation

- **RÂ² = 0.971** : Le modÃ¨le explique **97.1%** de la variance des donnÃ©es
  - Excellent (>0.9)
  - Risque de sur-apprentissage Ã  surveiller
  
- **MAE = 5.08** : En moyenne, le modÃ¨le se trompe de **5.08 passages aux urgences**
  - TrÃ¨s bon pour des valeurs allant de 0 Ã  plusieurs centaines
  
- **RMSE = 8.23** : PÃ©nalise davantage les grandes erreurs
  - LÃ©gÃ¨rement supÃ©rieur au MAE (normal)

### Importance des Features

**Top 10 des features les plus importantes** (selon les mÃ©moires) :

1. **passages_urgences_lag1** : Passages urgences semaine prÃ©cÃ©dente
2. **temperature_moyenne** : TempÃ©rature moyenne
3. **humidite** : HumiditÃ© relative
4. **pop_65_plus** : Population +65 ans
5. **densite** : DensitÃ© de population
6. **passages_urgences_ma3** : Moyenne mobile 3 semaines
7. **sin_semaine** : SaisonnalitÃ© (sin)
8. **cos_semaine** : SaisonnalitÃ© (cos)
9. **temp_humidite** : Interaction tempÃ©rature-humiditÃ©
10. **taux_urbanisation** : Taux d'urbanisation

---

## ðŸ”¬ Comparaison de ModÃ¨les

### ModÃ¨les TestÃ©s (Selon Architecture MÃ©moire)

D'aprÃ¨s la mÃ©moire systÃ¨me, plusieurs modÃ¨les ont Ã©tÃ© envisagÃ©s :

| ModÃ¨le | Type | Avantages | InconvÃ©nients | Statut |
|--------|------|-----------|---------------|--------|
| **Random Forest** | Ensemble | Robuste, performant | Lent, volumineux | âœ… **UTILISÃ‰** |
| **Ridge** | LinÃ©aire | Rapide, simple | Moins performant | ðŸ”„ EnvisagÃ© |
| **LightGBM** | Gradient Boosting | TrÃ¨s rapide, performant | Complexe | ðŸ”„ EnvisagÃ© |
| **XGBoost** | Gradient Boosting | TrÃ¨s performant | Complexe, lent | ðŸ”„ EnvisagÃ© |
| **ElasticNet** | LinÃ©aire | RÃ©gularisation L1+L2 | LinÃ©aire | ðŸ”„ EnvisagÃ© |
| **SARIMAX** | SÃ©rie temporelle | SpÃ©cialisÃ© temps | Complexe | ðŸ”„ EnvisagÃ© |

### Pourquoi Random Forest a Ã©tÃ© Choisi ?

1. **Ã‰quilibre performance/complexitÃ©** : Excellent RÂ² sans tuning intensif
2. **Robustesse** : GÃ¨re bien les outliers et valeurs manquantes
3. **InterprÃ©tabilitÃ©** : Feature importance claire
4. **StabilitÃ©** : RÃ©sultats reproductibles
5. **Pas de scaling requis** : Contrairement aux modÃ¨les linÃ©aires

---

## ðŸš€ EntraÃ®nement du ModÃ¨le

### Script d'EntraÃ®nement

**Fichier** : `ml/train_random_forest.py`

**Commande** :
```bash
python3 ml/train_random_forest.py
```

### Pipeline d'EntraÃ®nement

```
1. CHARGEMENT DU DATASET
   â†“ data/processed/clean_dataset.csv
   
2. PRÃ‰PARATION DES FEATURES
   â†“ SÃ©lection features numÃ©riques
   â†“ Exclusion colonnes non pertinentes
   
3. SPLIT TRAIN/TEST (80/20)
   â†“ Train: 80% des donnÃ©es
   â†“ Test: 20% des donnÃ©es
   
4. ENTRAÃŽNEMENT RANDOM FOREST
   â†“ 300 arbres, profondeur 10
   â†“ ParallÃ©lisation sur tous les CPU
   
5. Ã‰VALUATION
   â†“ Calcul MAE, RÂ², RMSE
   â†“ Analyse importance features
   
6. GÃ‰NÃ‰RATION PRÃ‰DICTIONS
   â†“ PrÃ©dictions sur tout le dataset
   â†“ Calcul Ã©carts et erreurs
   
7. SAUVEGARDE
   â†“ ml/artefacts/random_forest.pkl
   â†“ ml/artefacts/metrics.json
   â†“ ml/artefacts/feature_importance.csv
   â†“ data/processed/predictions.csv
```

### DurÃ©e d'EntraÃ®nement

- **Chargement** : ~1-2 secondes
- **PrÃ©paration** : ~1-2 secondes
- **EntraÃ®nement** : ~30-60 secondes (selon CPU)
- **Ã‰valuation** : ~5-10 secondes
- **Sauvegarde** : ~2-5 secondes

**Total** : ~1-2 minutes

---

## ðŸ“ Artefacts GÃ©nÃ©rÃ©s

AprÃ¨s l'entraÃ®nement, les fichiers suivants sont crÃ©Ã©s :

### 1. ModÃ¨le EntraÃ®nÃ©
**Fichier** : `ml/artefacts/random_forest.pkl`
- ModÃ¨le Random Forest sÃ©rialisÃ© (joblib)
- Utilisable pour prÃ©dictions futures
- Taille : ~5-50 MB (selon complexitÃ©)

### 2. MÃ©triques de Performance
**Fichier** : `ml/artefacts/metrics.json`
```json
{
  "model_type": "RandomForestRegressor",
  "target": "nb_passages",
  "features_count": 25,
  "train_samples": 3360,
  "test_samples": 840,
  "MAE": 5.08,
  "R2": 0.971,
  "timestamp": "2025-10-22T14:30:00"
}
```

### 3. Importance des Features
**Fichier** : `ml/artefacts/feature_importance.csv`
```csv
feature,importance
passages_urgences_lag1,0.3542
temperature_moyenne,0.1823
humidite,0.1245
...
```

**Graphique** : `ml/artefacts/feature_importance.png`
- Graphique en barres horizontales
- Visualisation de l'importance de chaque feature

### 4. PrÃ©dictions
**Fichier** : `data/processed/predictions.csv`
- Dataset complet avec prÃ©dictions
- Colonnes ajoutÃ©es :
  - `pred_nb_passages` : PrÃ©diction du modÃ¨le
  - `ecart` : DiffÃ©rence (rÃ©el - prÃ©dit)
  - `ecart_absolu` : Valeur absolue de l'Ã©cart
  - `ecart_pct` : Ã‰cart en pourcentage

### 5. Rapport de Performance
**Fichier** : `ml/artefacts/performance_report.json`
- Rapport dÃ©taillÃ© complet
- Statistiques sur les prÃ©dictions
- Informations sur le modÃ¨le

**Fichier** : `ml/artefacts/TRAINING_SUMMARY.txt`
- RÃ©sumÃ© lisible du training
- Top 5 features importantes
- MÃ©triques principales

---

## ðŸ”§ Optimisation et Tuning

### HyperparamÃ¨tres Ã  Ajuster

Si les performances ne sont pas satisfaisantes, voici les paramÃ¨tres Ã  modifier :

#### 1. Nombre d'Arbres (`n_estimators`)
```python
# Actuel: 300
# Augmenter pour plus de prÃ©cision (mais plus lent)
n_estimators=500  # Plus prÃ©cis
n_estimators=100  # Plus rapide
```

#### 2. Profondeur Maximale (`max_depth`)
```python
# Actuel: 10
# Augmenter si sous-apprentissage
max_depth=15  # Plus complexe
max_depth=5   # Plus simple (Ã©vite sur-apprentissage)
```

#### 3. Ã‰chantillons Minimum par Split
```python
# Ajouter pour Ã©viter sur-apprentissage
min_samples_split=10  # Minimum 10 Ã©chantillons pour split
min_samples_leaf=5    # Minimum 5 Ã©chantillons par feuille
```

#### 4. Features par Split
```python
# ContrÃ´ler la randomisation
max_features='sqrt'  # Racine carrÃ©e du nombre de features
max_features='log2'  # Log2 du nombre de features
max_features=0.5     # 50% des features
```

### Grid Search (Recherche Exhaustive)

Pour trouver les meilleurs hyperparamÃ¨tres :

```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 5]
}

grid_search = GridSearchCV(
    RandomForestRegressor(random_state=42),
    param_grid,
    cv=5,
    scoring='r2',
    n_jobs=-1
)

grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
```

---

## ðŸŽ¯ Variable Cible (Target)

### Variable PrÃ©dite

**Variable** : `nb_passages` (ou similaire selon le dataset)

**Description** : Nombre de passages aux urgences pour syndrome grippal

**Type** : Continue (rÃ©gression)

**Plage** : 0 Ã  plusieurs centaines

### Transformation de la Cible

Actuellement, **aucune transformation** n'est appliquÃ©e Ã  la cible.

**Transformations possibles** (si nÃ©cessaire) :
- **Log** : `log(y + 1)` pour rÃ©duire l'impact des valeurs extrÃªmes
- **Standardisation** : `(y - mean) / std` pour normaliser
- **Binning** : Transformer en classes (classification)

---

## ðŸ“ˆ Ã‰volution Future

### ModÃ¨les Ã  Tester

1. **LightGBM** ðŸš€
   - Plus rapide que Random Forest
   - TrÃ¨s performant sur gros datasets
   - Moins de mÃ©moire requise

2. **XGBoost** ðŸ’ª
   - Souvent meilleur que Random Forest
   - RÃ©gularisation intÃ©grÃ©e
   - Gestion native des valeurs manquantes

3. **Ridge/Lasso** âš¡
   - TrÃ¨s rapides
   - Bons pour baseline
   - InterprÃ©tables

4. **SARIMAX** ðŸ“…
   - SpÃ©cialisÃ© sÃ©ries temporelles
   - Capture saisonnalitÃ©
   - PrÃ©dictions Ã  long terme

### Ensemble de ModÃ¨les

**Stacking** : Combiner plusieurs modÃ¨les

```python
from sklearn.ensemble import StackingRegressor

estimators = [
    ('rf', RandomForestRegressor()),
    ('gb', GradientBoostingRegressor()),
    ('ridge', Ridge())
]

stacking = StackingRegressor(
    estimators=estimators,
    final_estimator=Ridge()
)
```

---

## ðŸ” Diagnostic et Monitoring

### VÃ©rifier les Performances

```bash
# Voir les mÃ©triques
cat ml/artefacts/metrics.json

# Voir le rÃ©sumÃ©
cat ml/artefacts/TRAINING_SUMMARY.txt

# Voir l'importance des features
cat ml/artefacts/feature_importance.csv
```

### Signes de Sur-Apprentissage

âš ï¸ **Attention si** :
- RÂ² train >> RÂ² test (Ã©cart >0.1)
- RÂ² = 1.000 (trop parfait)
- MAE train << MAE test

**Solutions** :
- RÃ©duire `max_depth`
- Augmenter `min_samples_split`
- Augmenter `min_samples_leaf`
- Ajouter plus de donnÃ©es

### Signes de Sous-Apprentissage

âš ï¸ **Attention si** :
- RÂ² < 0.7 (mauvais)
- MAE trÃ¨s Ã©levÃ©
- PrÃ©dictions plates (peu de variance)

**Solutions** :
- Augmenter `max_depth`
- Augmenter `n_estimators`
- Ajouter plus de features
- Essayer un modÃ¨le plus complexe (XGBoost)

---

## ðŸ“š Ressources

### Documentation scikit-learn
- [Random Forest Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
- [Ensemble Methods](https://scikit-learn.org/stable/modules/ensemble.html)

### Tutoriels
- [Random Forest Explained](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)
- [Hyperparameter Tuning](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)

---

## ðŸ“ž Commandes Utiles

```bash
# EntraÃ®ner le modÃ¨le
python3 ml/train_random_forest.py

# Voir les mÃ©triques
cat ml/artefacts/metrics.json | python3 -m json.tool

# Voir l'importance des features
cat ml/artefacts/feature_importance.csv | column -t -s,

# Charger le modÃ¨le en Python
python3 -c "import joblib; model = joblib.load('ml/artefacts/random_forest.pkl'); print(model)"
```

---

**ðŸ¤– LUMEN Enhanced - Machine Learning**

*Random Forest â€¢ Performance â€¢ Robustesse*
