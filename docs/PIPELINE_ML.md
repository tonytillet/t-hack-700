# ğŸ¤– LUMEN - Pipeline Machine Learning Complet

## ğŸ“‹ Table des MatiÃ¨res
- [Vue d'ensemble du Pipeline](#vue-densemble-du-pipeline)
- [Pipeline Complet Ã‰tape par Ã‰tape](#pipeline-complet-Ã©tape-par-Ã©tape)
- [Ordre d'ExÃ©cution des Scripts](#ordre-dexÃ©cution-des-scripts)
- [Commandes Makefile](#commandes-makefile)
- [Flux de DonnÃ©es](#flux-de-donnÃ©es)
- [Exemples Pratiques](#exemples-pratiques)

---

## ğŸ¯ Vue d'ensemble du Pipeline

Le pipeline LUMEN suit un processus en **7 Ã©tapes** pour transformer les donnÃ©es brutes en prÃ©dictions ML :

```
ğŸ“¥ DONNÃ‰ES BRUTES
    â†“
ğŸ§¹ NETTOYAGE (clean_data_controlled.py)
    â†“
âœ… VALIDATION (validate_data_strict.py)
    â†“
ğŸ”„ FUSION & FEATURES (generate_meaningful_data.py)
    â†“
ğŸ¤– ENTRAÃNEMENT ML (ml/train_random_forest.py)
    â†“
ğŸ“Š GÃ‰NÃ‰RATION DASHBOARDS (dashboard_integration.py)
    â†“
ğŸ” EXPLICABILITÃ‰ (explicabilite_shap.py)
    â†“
ğŸŒ SERVEUR (serveur_simple.py)
```

---

## ğŸ“Š Pipeline Complet Ã‰tape par Ã‰tape

### ğŸ”¹ Ã‰tape 0 : PrÃ©paration (Optionnel)

**Script** : Aucun (donnÃ©es dÃ©jÃ  prÃ©sentes)

**Objectif** : Avoir des donnÃ©es brutes dans `data/raw/`

**DonnÃ©es sources** :
- SantÃ© Publique France (SPF) : DonnÃ©es Ã©pidÃ©miologiques
- MÃ©tÃ©o France : DonnÃ©es mÃ©tÃ©orologiques
- INSEE : DonnÃ©es dÃ©mographiques
- Data.gouv.fr : DonnÃ©es ouvertes

**Commande** :
```bash
# VÃ©rifier les donnÃ©es brutes
ls -la data/raw/
```

**RÃ©sultat attendu** :
```
data/raw/
â”œâ”€â”€ spf_data.csv              (donnÃ©es SPF)
â”œâ”€â”€ meteo_data.csv            (donnÃ©es mÃ©tÃ©o)
â”œâ”€â”€ insee_data.csv            (donnÃ©es INSEE)
â””â”€â”€ data.gouv.fr_*.json       (donnÃ©es data.gouv.fr)
```

---

### ğŸ”¹ Ã‰tape 1 : Nettoyage des DonnÃ©es

**Script** : `clean_data_controlled.py`

**Objectif** : Nettoyer et standardiser les donnÃ©es brutes

**Processus** :
1. ğŸ“‚ Lecture des donnÃ©es brutes depuis `data/raw/`
2. ğŸ§¹ Nettoyage avec **Dataprep** :
   - Suppression des doublons
   - Gestion des valeurs manquantes
   - Normalisation des formats
   - Harmonisation des libellÃ©s
3. ğŸ” Calcul des checksums SHA256
4. ğŸ“‹ GÃ©nÃ©ration d'un rapport de nettoyage
5. ğŸ’¾ Sauvegarde dans `data/cleaned/`

**Commande** :
```bash
# MÃ©thode 1 : Direct
python3 clean_data_controlled.py

# MÃ©thode 2 : Makefile
make clean-validate
```

**DurÃ©e** : ~30-60 secondes

**Fichiers gÃ©nÃ©rÃ©s** :
```
data/cleaned/
â”œâ”€â”€ spf_data_cleaned.csv
â”œâ”€â”€ meteo_data_cleaned.csv
â”œâ”€â”€ insee_data_cleaned.csv
â””â”€â”€ cleaning_report_YYYYMMDD_HHMMSS.json
```

**Sortie attendue** :
```
ğŸ§¹ NETTOYAGE CONTRÃ”LÃ‰ DES DONNÃ‰ES
==================================
ğŸ“‚ Lecture des donnÃ©es brutes...
âœ… 4 fichiers trouvÃ©s

ğŸ§¹ Nettoyage en cours...
  â€¢ spf_data.csv: 4,317 lignes â†’ 4,200 lignes (117 doublons supprimÃ©s)
  â€¢ meteo_data.csv: 3,939 lignes â†’ 3,900 lignes (39 doublons supprimÃ©s)
  â€¢ insee_data.csv: 13 lignes â†’ 13 lignes (0 doublons)

ğŸ” Calcul des checksums SHA256...
âœ… Checksums calculÃ©s

ğŸ“‹ Rapport de nettoyage gÃ©nÃ©rÃ©
ğŸ’¾ DonnÃ©es sauvegardÃ©es dans data/cleaned/

âœ… NETTOYAGE TERMINÃ‰
```

---

### ğŸ”¹ Ã‰tape 2 : Validation des DonnÃ©es

**Script** : `validate_data_strict.py`

**Objectif** : Valider strictement les donnÃ©es nettoyÃ©es avec **Pandera**

**Processus** :
1. ğŸ“‚ Lecture des donnÃ©es nettoyÃ©es depuis `data/cleaned/`
2. âœ… Validation avec **Pandera** :
   - VÃ©rification des types de donnÃ©es
   - VÃ©rification des plages de valeurs
   - VÃ©rification de la cohÃ©rence temporelle
   - DÃ©tection des anomalies
3. ğŸ“Š GÃ©nÃ©ration de statistiques
4. ğŸ“‹ GÃ©nÃ©ration d'un rapport de validation
5. ğŸ’¾ Sauvegarde dans `data/validated/`

**Commande** :
```bash
# MÃ©thode 1 : Direct
python3 validate_data_strict.py

# MÃ©thode 2 : Makefile
make validate-strict
```

**DurÃ©e** : ~20-40 secondes

**Fichiers gÃ©nÃ©rÃ©s** :
```
data/validated/
â”œâ”€â”€ spf_data_validated.parquet
â”œâ”€â”€ meteo_data_validated.parquet
â”œâ”€â”€ insee_data_validated.parquet
â””â”€â”€ validation_report_YYYYMMDD_HHMMSS.json
```

**Sortie attendue** :
```
âœ… VALIDATION STRICTE DES DONNÃ‰ES
==================================
ğŸ“‚ Lecture des donnÃ©es nettoyÃ©es...
âœ… 3 fichiers trouvÃ©s

ğŸ” Validation en cours...
  â€¢ spf_data_cleaned.csv: âœ… VALIDE (4,200 lignes)
  â€¢ meteo_data_cleaned.csv: âœ… VALIDE (3,900 lignes)
  â€¢ insee_data_cleaned.csv: âœ… VALIDE (13 lignes)

ğŸ“Š Statistiques:
  â€¢ Total lignes validÃ©es: 8,113
  â€¢ Anomalies dÃ©tectÃ©es: 0
  â€¢ Taux de validation: 100%

ğŸ“‹ Rapport de validation gÃ©nÃ©rÃ©
ğŸ’¾ DonnÃ©es sauvegardÃ©es dans data/validated/

âœ… VALIDATION TERMINÃ‰E
```

---

### ğŸ”¹ Ã‰tape 3 : Fusion et Feature Engineering

**Script** : `generate_meaningful_data.py` (ou fusion automatique)

**Objectif** : Fusionner les donnÃ©es et crÃ©er les features pour le ML

**Processus** :
1. ğŸ“‚ Lecture des donnÃ©es validÃ©es depuis `data/validated/`
2. ğŸ”— Fusion des datasets :
   - SPF + MÃ©tÃ©o (par date et rÃ©gion)
   - SPF + INSEE (par rÃ©gion)
3. ğŸ› ï¸ Feature Engineering :
   - **Lags** : 1-4 semaines
   - **Moyennes mobiles** : 3 et 7 semaines
   - **SaisonnalitÃ©** : Fourier series (sin/cos)
   - **Features temporelles** : jour, mois, trimestre
   - **Features d'interaction** : tempÃ©rature Ã— humiditÃ©
4. ğŸ’¾ Sauvegarde dans `data/processed/`

**Commande** :
```bash
python3 generate_meaningful_data.py
```

**DurÃ©e** : ~10-20 secondes

**Fichiers gÃ©nÃ©rÃ©s** :
```
data/processed/
â”œâ”€â”€ dataset.parquet              (dataset complet)
â””â”€â”€ features_description.json    (description des features)
```

**Features crÃ©Ã©es** (exemple) :
```
- passages_urgences_grippe       (cible)
- passages_urgences_lag1         (lag 1 semaine)
- passages_urgences_lag2         (lag 2 semaines)
- passages_urgences_ma7          (moyenne mobile 7 jours)
- temperature_moyenne
- humidite_moyenne
- taux_incidence
- couverture_vaccinale
- saison_sin                     (saisonnalitÃ©)
- saison_cos                     (saisonnalitÃ©)
- temp_x_humidite                (interaction)
```

**Sortie attendue** :
```
ğŸ”— FUSION ET FEATURE ENGINEERING
=================================
ğŸ“‚ Lecture des donnÃ©es validÃ©es...
âœ… 3 datasets trouvÃ©s

ğŸ”— Fusion des datasets...
âœ… SPF + MÃ©tÃ©o fusionnÃ©s (4,200 lignes)
âœ… SPF + INSEE fusionnÃ©s (4,200 lignes)

ğŸ› ï¸ Feature Engineering...
âœ… Lags crÃ©Ã©s (1-4 semaines)
âœ… Moyennes mobiles crÃ©Ã©es (3, 7 semaines)
âœ… SaisonnalitÃ© crÃ©Ã©e (sin/cos)
âœ… Features temporelles crÃ©Ã©es
âœ… Features d'interaction crÃ©Ã©es

ğŸ“Š Dataset final:
  â€¢ Lignes: 4,200
  â€¢ Colonnes: 25 features
  â€¢ Taille: 2.5 MB

ğŸ’¾ Dataset sauvegardÃ© dans data/processed/

âœ… FUSION TERMINÃ‰E
```

---

### ğŸ”¹ Ã‰tape 4 : EntraÃ®nement du ModÃ¨le ML

**Script** : `ml/train_random_forest.py`

**Objectif** : EntraÃ®ner le modÃ¨le Random Forest pour prÃ©dire la grippe

**Processus** :
1. ğŸ“‚ Lecture du dataset depuis `data/processed/dataset.parquet`
2. ğŸ”€ Split train/test (70/30 chronologique)
3. ğŸ¤– EntraÃ®nement du Random Forest :
   - n_estimators=100
   - max_depth=8
   - min_samples_split=10
   - min_samples_leaf=5
4. ğŸ“Š Ã‰valuation des performances (RÂ², MAE, RMSE)
5. ğŸ“ˆ Calcul de l'importance des features
6. ğŸ’¾ Sauvegarde du modÃ¨le dans `models/`

**Commande** :
```bash
python3 ml/train_random_forest.py
```

**DurÃ©e** : ~1-3 minutes

**Fichiers gÃ©nÃ©rÃ©s** :
```
models/
â”œâ”€â”€ random_forest_regressor_YYYYMMDD_HHMMSS.joblib  (modÃ¨le)
â””â”€â”€ ml/artefacts/
    â”œâ”€â”€ metrics.json                                 (mÃ©triques)
    â”œâ”€â”€ feature_importance.csv                       (importance)
    â””â”€â”€ training_report.txt                          (rapport)
```

**Sortie attendue** :
```
ğŸ¤– ENTRAÃNEMENT DU MODÃˆLE RANDOM FOREST
========================================
ğŸ“‚ Chargement des donnÃ©es...
âœ… Dataset chargÃ©: 4,200 lignes, 25 features

ğŸ”€ Split train/test...
âœ… Train: 2,940 lignes (70%)
âœ… Test: 1,260 lignes (30%)

ğŸ¤– EntraÃ®nement en cours...
âœ… ModÃ¨le entraÃ®nÃ© (100 arbres)

ğŸ“Š PERFORMANCES:
  â€¢ RÂ² Score: 0.971 (97.1%)
  â€¢ MAE: 5.08
  â€¢ RMSE: 8.23

ğŸ“ˆ TOP 5 FEATURES:
  1. passages_urgences_lag1 (0.35)
  2. passages_urgences_ma7 (0.22)
  3. temperature_moyenne (0.15)
  4. saison_sin (0.12)
  5. taux_incidence (0.08)

ğŸ’¾ ModÃ¨le sauvegardÃ©: models/random_forest_regressor_20251022_115500.joblib

âœ… ENTRAÃNEMENT TERMINÃ‰
```

---

### ğŸ”¹ Ã‰tape 5 : GÃ©nÃ©ration des Dashboards

**Script** : `dashboard_integration.py`

**Objectif** : GÃ©nÃ©rer les dashboards HTML interactifs avec Plotly

**Processus** :
1. ğŸ“‚ Chargement du dataset depuis `data/processed/dataset.parquet`
2. ğŸ¤– Chargement du modÃ¨le depuis `models/`
3. ğŸ”® GÃ©nÃ©ration des prÃ©dictions
4. ğŸ“Š Calcul des niveaux d'alerte (VERT, JAUNE, ORANGE, ROUGE)
5. ğŸ¨ CrÃ©ation des visualisations :
   - Carte des zones Ã  risque
   - Graphiques rÃ©el vs prÃ©dit
   - Panneau des alertes actives
6. ğŸ’¾ Sauvegarde des dashboards HTML

**Commande** :
```bash
python3 dashboard_integration.py
```

**DurÃ©e** : ~10-30 secondes

**Fichiers gÃ©nÃ©rÃ©s** :
```
./ (racine)
â”œâ”€â”€ dashboard_risk_heatmap.html           (carte)
â”œâ”€â”€ dashboard_real_vs_predicted.html      (graphiques)
â””â”€â”€ dashboard_active_alerts.html          (alertes)
```

**Sortie attendue** :
```
ğŸ¯ LUMEN - INTÃ‰GRATION DASHBOARD AVANCÃ‰E
=========================================
ğŸ“Š CHARGEMENT DES DONNÃ‰ES ET DU MODÃˆLE
âœ… DonnÃ©es chargÃ©es: 4,200 lignes
âœ… ModÃ¨le chargÃ©: random_forest_regressor_20251022_115500.joblib

ğŸ”® GÃ‰NÃ‰RATION DES PRÃ‰DICTIONS
âœ… PrÃ©dictions gÃ©nÃ©rÃ©es pour 4,200 Ã©chantillons
ğŸ“Š Niveaux d'alerte: {'ROUGE': 150, 'ORANGE': 300, 'JAUNE': 500, 'VERT': 3250}

ğŸ¨ CRÃ‰ATION DES VISUALISATIONS
âœ… Carte des zones Ã  risque sauvegardÃ©e
âœ… Graphique rÃ©el vs prÃ©dit sauvegardÃ©
âœ… Panneau des alertes actives sauvegardÃ©
ğŸ“Š 7 alertes actives dÃ©tectÃ©es

âœ… INTÃ‰GRATION DASHBOARD TERMINÃ‰E
```

---

### ğŸ”¹ Ã‰tape 6 : ExplicabilitÃ© SHAP (Optionnel)

**Script** : `explicabilite_shap.py`

**Objectif** : GÃ©nÃ©rer les plots SHAP pour expliquer les prÃ©dictions

**Processus** :
1. ğŸ“‚ Chargement du modÃ¨le depuis `models/`
2. ğŸ“‚ Chargement du dataset de test
3. ğŸ” Calcul des valeurs SHAP
4. ğŸ“Š GÃ©nÃ©ration de 15 plots :
   - Summary plot
   - Waterfall plot
   - Force plot
   - Dependence plots
   - Feature importance
5. ğŸ’¾ Sauvegarde dans `explicabilite/`

**Commande** :
```bash
python3 explicabilite_shap.py
```

**DurÃ©e** : ~1-2 minutes

**Fichiers gÃ©nÃ©rÃ©s** :
```
explicabilite/
â”œâ”€â”€ shap_summary_plot.png
â”œâ”€â”€ shap_waterfall_plot.png
â”œâ”€â”€ shap_force_plot.html
â”œâ”€â”€ shap_dependence_*.png (x10)
â””â”€â”€ shap_feature_importance.png
```

**Sortie attendue** :
```
ğŸ” EXPLICABILITÃ‰ SHAP
=====================
ğŸ“‚ Chargement du modÃ¨le...
âœ… ModÃ¨le chargÃ©

ğŸ“‚ Chargement des donnÃ©es de test...
âœ… 1,260 Ã©chantillons de test

ğŸ” Calcul des valeurs SHAP...
âœ… Valeurs SHAP calculÃ©es

ğŸ“Š GÃ©nÃ©ration des plots...
âœ… Summary plot gÃ©nÃ©rÃ©
âœ… Waterfall plot gÃ©nÃ©rÃ©
âœ… Force plot gÃ©nÃ©rÃ©
âœ… Dependence plots gÃ©nÃ©rÃ©s (10)
âœ… Feature importance gÃ©nÃ©rÃ©

ğŸ’¾ 15 plots sauvegardÃ©s dans explicabilite/

âœ… EXPLICABILITÃ‰ TERMINÃ‰E
```

---

### ğŸ”¹ Ã‰tape 7 : Lancement du Serveur

**Script** : `serveur_simple.py`

**Objectif** : Lancer le serveur HTTP pour afficher les dashboards

**Processus** :
1. âœ… VÃ©rification des fichiers HTML
2. ğŸŒ DÃ©marrage du serveur HTTP sur port 8080
3. ğŸ”„ Redirection automatique vers le dashboard principal
4. ğŸ“Š Service des dashboards HTML

**Commande** :
```bash
# MÃ©thode 1 : Direct
python3 serveur_simple.py

# MÃ©thode 2 : Script automatique
./start.sh
```

**DurÃ©e** : InstantanÃ©

**Sortie attendue** :
```
ğŸŒ LUMEN - SERVEUR UNIFIÃ‰
========================================
ğŸš€ Port unique: 8080
ğŸ“Š Dashboard principal: http://localhost:8080/
ğŸ—ºï¸ Carte des risques: http://localhost:8080/dashboard_risk_heatmap.html
ğŸ“ˆ PrÃ©dictions: http://localhost:8080/dashboard_real_vs_predicted.html
ğŸš¨ Alertes actives: http://localhost:8080/dashboard_active_alerts.html
========================================
âœ… Tous les dashboards sont prÃªts
ğŸŒ Serveur dÃ©marrÃ©: http://localhost:8080
ğŸ›‘ Ctrl+C pour arrÃªter
```

---

## ğŸš€ Ordre d'ExÃ©cution des Scripts

### ğŸ“ Pipeline Complet Manuel

```bash
# 1. Nettoyage des donnÃ©es
python3 clean_data_controlled.py

# 2. Validation des donnÃ©es
python3 validate_data_strict.py

# 3. Fusion et feature engineering
python3 generate_meaningful_data.py

# 4. EntraÃ®nement du modÃ¨le ML
python3 ml/train_random_forest.py

# 5. GÃ©nÃ©ration des dashboards
python3 dashboard_integration.py

# 6. ExplicabilitÃ© SHAP (optionnel)
python3 explicabilite_shap.py

# 7. Lancement du serveur
python3 serveur_simple.py
```

**DurÃ©e totale** : ~5-10 minutes

---

### âš¡ Pipeline Complet Automatique (Makefile)

```bash
# Pipeline complet de validation des donnÃ©es
make full-pipeline

# Puis entraÃ®nement ML et dashboards
python3 ml/train_random_forest.py
python3 dashboard_integration.py
python3 serveur_simple.py
```

**DurÃ©e totale** : ~5-10 minutes

---

### ğŸ¯ Pipeline Rapide (Script start.sh)

```bash
# Lance directement le serveur (suppose que les dashboards existent)
./start.sh
```

**DurÃ©e totale** : ~10 secondes

---

## ğŸ“Š Commandes Makefile

Le `Makefile` fournit des commandes pratiques pour le pipeline :

### Commandes Principales

```bash
# Afficher l'aide
make help

# Pipeline complet de validation
make full-pipeline
  â†“
  â”œâ”€â”€ make clean-validate    (nettoyage)
  â”œâ”€â”€ make validate-strict   (validation)
  â”œâ”€â”€ make audit-ge          (audit)
  â”œâ”€â”€ make version-dvc       (versioning)
  â””â”€â”€ make evidence-pack     (bundle de preuve)

# VÃ©rifier l'Ã©tat du pipeline
make status

# GÃ©nÃ©rer un rapport de qualitÃ©
make quality-report

# Nettoyer les fichiers temporaires
make clean

# Installer les dÃ©pendances
make install-deps

# Tester l'intÃ©gritÃ©
make test-integrity
```

### DÃ©tail des Commandes

#### `make clean-validate`
```bash
make clean-validate
```
- ExÃ©cute `clean_data_controlled.py`
- Nettoie les donnÃ©es brutes
- GÃ©nÃ¨re `data/cleaned/*.csv`

#### `make validate-strict`
```bash
make validate-strict
```
- ExÃ©cute `validate_data_strict.py`
- Valide les donnÃ©es nettoyÃ©es
- GÃ©nÃ¨re `data/validated/*.parquet`

#### `make full-pipeline`
```bash
make full-pipeline
```
- ExÃ©cute toutes les Ã©tapes de validation
- Ã‰quivalent Ã  :
  ```bash
  make clean-validate
  make validate-strict
  make audit-ge
  make version-dvc
  make evidence-pack
  ```

#### `make status`
```bash
make status
```
- Affiche l'Ã©tat du pipeline
- Compte les fichiers dans chaque rÃ©pertoire
- **Sortie** :
  ```
  ğŸ“Š Ã‰TAT DU PIPELINE
  ===================
  ğŸ“ DonnÃ©es brutes: 4 fichiers
  ğŸ§¹ DonnÃ©es nettoyÃ©es: 3 fichiers
  âœ… DonnÃ©es validÃ©es: 3 fichiers
  ğŸ§Š DonnÃ©es gelÃ©es: 4 fichiers
  ğŸ“‹ Logs: 12 fichiers
  ğŸ“¦ Bundle de preuve: 9 fichiers
  ```

---

## ğŸ”„ Flux de DonnÃ©es

### Structure des RÃ©pertoires

```
t-hack-700/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # ğŸ“¥ DonnÃ©es brutes (sources)
â”‚   â”‚   â”œâ”€â”€ spf_data.csv
â”‚   â”‚   â”œâ”€â”€ meteo_data.csv
â”‚   â”‚   â””â”€â”€ insee_data.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ frozen/                 # ğŸ§Š DonnÃ©es gelÃ©es (snapshots)
â”‚   â”‚   â””â”€â”€ 2025-10-21_*.csv
â”‚   â”‚
â”‚   â”œâ”€â”€ cleaned/                # ğŸ§¹ DonnÃ©es nettoyÃ©es
â”‚   â”‚   â”œâ”€â”€ spf_data_cleaned.csv
â”‚   â”‚   â””â”€â”€ cleaning_report.json
â”‚   â”‚
â”‚   â”œâ”€â”€ validated/              # âœ… DonnÃ©es validÃ©es
â”‚   â”‚   â”œâ”€â”€ spf_data_validated.parquet
â”‚   â”‚   â””â”€â”€ validation_report.json
â”‚   â”‚
â”‚   â””â”€â”€ processed/              # ğŸ”— DonnÃ©es fusionnÃ©es + features
â”‚       â””â”€â”€ dataset.parquet
â”‚
â”œâ”€â”€ models/                     # ğŸ¤– ModÃ¨les ML entraÃ®nÃ©s
â”‚   â””â”€â”€ random_forest_regressor_*.joblib
â”‚
â”œâ”€â”€ ml/artefacts/               # ğŸ“Š MÃ©triques et rapports ML
â”‚   â”œâ”€â”€ metrics.json
â”‚   â””â”€â”€ feature_importance.csv
â”‚
â”œâ”€â”€ explicabilite/              # ğŸ” Plots SHAP
â”‚   â””â”€â”€ shap_*.png
â”‚
â”œâ”€â”€ evidence/                   # ğŸ“¦ Bundle de preuve
â”‚   â””â”€â”€ *.json
â”‚
â””â”€â”€ monitoring/logs/            # ğŸ“‹ Logs de monitoring
    â””â”€â”€ *.log
```

### Flux de Transformation

```
ğŸ“¥ DONNÃ‰ES BRUTES (data/raw/)
    â†“ clean_data_controlled.py
ğŸ§¹ DONNÃ‰ES NETTOYÃ‰ES (data/cleaned/)
    â†“ validate_data_strict.py
âœ… DONNÃ‰ES VALIDÃ‰ES (data/validated/)
    â†“ generate_meaningful_data.py
ğŸ”— DATASET COMPLET (data/processed/)
    â†“ ml/train_random_forest.py
ğŸ¤– MODÃˆLE ML (models/)
    â†“ dashboard_integration.py
ğŸ“Š DASHBOARDS HTML (racine)
    â†“ serveur_simple.py
ğŸŒ SERVEUR WEB (http://localhost:8080)
```

---

## ğŸ’¡ Exemples Pratiques

### Exemple 1 : Premier Lancement Complet

```bash
# 1. Installer les dÃ©pendances
pip install -r requirements.txt

# 2. ExÃ©cuter le pipeline de validation
make full-pipeline

# 3. Fusionner et crÃ©er les features
python3 generate_meaningful_data.py

# 4. EntraÃ®ner le modÃ¨le
python3 ml/train_random_forest.py

# 5. GÃ©nÃ©rer les dashboards
python3 dashboard_integration.py

# 6. Lancer le serveur
./start.sh
```

---

### Exemple 2 : RÃ©-entraÃ®nement Rapide

```bash
# Si les donnÃ©es sont dÃ©jÃ  validÃ©es, juste rÃ©-entraÃ®ner
python3 ml/train_random_forest.py
python3 dashboard_integration.py
python3 serveur_simple.py
```

---

### Exemple 3 : Ajout de Nouvelles DonnÃ©es

```bash
# 1. Ajouter les nouvelles donnÃ©es dans data/raw/

# 2. Nettoyer les nouvelles donnÃ©es
python3 clean_data_controlled.py

# 3. Valider
python3 validate_data_strict.py

# 4. Fusionner
python3 generate_meaningful_data.py

# 5. RÃ©-entraÃ®ner
python3 ml/train_random_forest.py

# 6. RÃ©gÃ©nÃ©rer les dashboards
python3 dashboard_integration.py
```

---

### Exemple 4 : Monitoring Automatique

```bash
# Configuration du crontab pour monitoring automatique

# Ã‰diter le crontab
crontab -e

# Ajouter ces lignes :
# Monitoring quotidien Ã  6h00
0 6 * * * cd /path/to/t-hack-700 && bash monitoring/daily_monitoring.sh

# Retrain hebdomadaire tous les dimanches Ã  2h00
0 2 * * 0 cd /path/to/t-hack-700 && bash monitoring/weekly_retrain.sh
```

---

## ğŸ¯ RÃ©sumÃ©

### Pipeline Minimal (Lancement Rapide)
```bash
./start.sh
```

### Pipeline Complet (PremiÃ¨re Fois)
```bash
make full-pipeline
python3 generate_meaningful_data.py
python3 ml/train_random_forest.py
python3 dashboard_integration.py
./start.sh
```

### Pipeline de RÃ©-entraÃ®nement
```bash
python3 ml/train_random_forest.py
python3 dashboard_integration.py
python3 serveur_simple.py
```

---

## ğŸ“Š Tableau RÃ©capitulatif

| Ã‰tape | Script | DurÃ©e | Fichiers GÃ©nÃ©rÃ©s |
|-------|--------|-------|------------------|
| 1. Nettoyage | `clean_data_controlled.py` | 30-60s | `data/cleaned/*.csv` |
| 2. Validation | `validate_data_strict.py` | 20-40s | `data/validated/*.parquet` |
| 3. Fusion | `generate_meaningful_data.py` | 10-20s | `data/processed/dataset.parquet` |
| 4. ML | `ml/train_random_forest.py` | 1-3min | `models/*.joblib` |
| 5. Dashboards | `dashboard_integration.py` | 10-30s | `dashboard_*.html` |
| 6. SHAP | `explicabilite_shap.py` | 1-2min | `explicabilite/*.png` |
| 7. Serveur | `serveur_simple.py` | Instant | - |

**DurÃ©e totale** : ~5-10 minutes

---

## ğŸ‰ Conclusion

Le pipeline LUMEN est conÃ§u pour Ãªtre :
- âœ… **AutomatisÃ©** : Makefile et scripts shell
- âœ… **Modulaire** : Chaque Ã©tape indÃ©pendante
- âœ… **TraÃ§able** : Logs et rapports Ã  chaque Ã©tape
- âœ… **Reproductible** : Checksums et versioning
- âœ… **Explicable** : SHAP pour l'explicabilitÃ©

Tu peux maintenant lancer le pipeline complet ou juste les Ã©tapes dont tu as besoin ! ğŸš€
