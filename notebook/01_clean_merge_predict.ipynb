{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e18181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Fichiers d√©tect√©s : ['doses-actes-2024.csv', 'inc-3-RDD-ds2.csv', 'couverture-2024.csv', 'santefr-lieux-vaccination-grippe-pharmacie.csv', 'Openhealth_S-Grippal_Regions.csv', 'couvertures-vaccinales-des-adolescents-et-adultes-depuis-2011-france.csv', 'grippe-passages-aux-urgences-et-actes-sos-medecins-departement.csv', 'inc-3-PAY-ds2.csv', 'grippe-passages-urgences-et-actes-sos-medecin_reg.csv', 'campagne-2024.csv', 'clean', 'grippe-passages-aux-urgences-et-actes-sos-medecins-france.csv', 'couvertures-vaccinales-des-adolescent-et-adultes-departement.csv', 'couvertures-vaccinales-des-adolescents-et-adultes-depuis-2011-region.csv', 'Openhealth_S-Grippal.csv']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date_de_passage'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/epitech/T-HAK-700/t-hack-700/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'date_de_passage'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 58\u001b[39m\n\u001b[32m     56\u001b[39m grippe_fr = pd.read_csv(data_path + \u001b[33m\"\u001b[39m\u001b[33mgrippe-passages-aux-urgences-et-actes-sos-medecins-france.csv\u001b[39m\u001b[33m\"\u001b[39m, sep=\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, low_memory=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     57\u001b[39m grippe_fr = normalize_cols(grippe_fr)\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m grippe_fr = \u001b[43mto_weekly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrippe_fr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate_de_passage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnombre_de_passages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m grippe_fr.rename(columns={\u001b[33m\"\u001b[39m\u001b[33mnombre_de_passages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcas_grippe_fr\u001b[39m\u001b[33m\"\u001b[39m}, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     60\u001b[39m grippe_fr.to_csv(clean_path + \u001b[33m\"\u001b[39m\u001b[33mgrippe_fr_clean.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mto_weekly\u001b[39m\u001b[34m(df, date_col, value_col, agg)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_weekly\u001b[39m(df, date_col, value_col, agg=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convertit une colonne date en hebdomadaire\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     df[date_col] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_col\u001b[49m\u001b[43m]\u001b[49m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     40\u001b[39m     df = df.dropna(subset=[date_col])\n\u001b[32m     41\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mweek\u001b[39m\u001b[33m\"\u001b[39m] = df[date_col].dt.to_period(\u001b[33m\"\u001b[39m\u001b[33mW\u001b[39m\u001b[33m\"\u001b[39m).apply(\u001b[38;5;28;01mlambda\u001b[39;00m r: r.start_time)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/epitech/T-HAK-700/t-hack-700/venv/lib/python3.12/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/epitech/T-HAK-700/t-hack-700/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'date_de_passage'"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 1Ô∏è‚É£ IMPORTS ET CONFIGURATION G√âN√âRALE\n",
    "# =============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# --- chemins ---\n",
    "data_path = \"../data/\"\n",
    "clean_path = \"../data/clean/\"\n",
    "\n",
    "# Cr√©e le dossier clean s‚Äôil n‚Äôexiste pas\n",
    "os.makedirs(clean_path, exist_ok=True)\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "print(\"üìÇ Fichiers d√©tect√©s :\", files)\n",
    "\n",
    "# =============================================================\n",
    "# 2Ô∏è‚É£ FONCTIONS DE NETTOYAGE G√âN√âRIQUES\n",
    "# =============================================================\n",
    "\n",
    "def normalize_cols(df):\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(\" \", \"_\")\n",
    "        .str.replace(\"-\", \"_\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def to_weekly(df, date_col, value_col, agg=\"mean\"):\n",
    "    \"\"\"Convertit une colonne date en hebdomadaire\"\"\"\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[date_col])\n",
    "    df[\"week\"] = df[date_col].dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "    df = df.groupby(\"week\")[value_col].agg(agg).reset_index()\n",
    "    df.rename(columns={\"week\": \"date\"}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def regional_mean(df, region_col, value_col):\n",
    "    \"\"\"Calcule la moyenne nationale √† partir des valeurs r√©gionales\"\"\"\n",
    "    return df.groupby([\"date\"])[value_col].mean().reset_index()\n",
    "\n",
    "# =============================================================\n",
    "# 3Ô∏è‚É£ LECTURE ET NETTOYAGE PERSONNALIS√â DES FICHIERS\n",
    "# =============================================================\n",
    "\n",
    "# --- A. Grippe : urgences France enti√®re ---\n",
    "grippe_fr = pd.read_csv(data_path + \"grippe-passages-aux-urgences-et-actes-sos-medecins-france.csv\", sep=\";\", low_memory=False)\n",
    "grippe_fr = normalize_cols(grippe_fr)\n",
    "grippe_fr = to_weekly(grippe_fr, date_col=\"date_de_passage\", value_col=\"nombre_de_passages\", agg=\"sum\")\n",
    "grippe_fr.rename(columns={\"nombre_de_passages\": \"cas_grippe_fr\"}, inplace=True)\n",
    "grippe_fr.to_csv(clean_path + \"grippe_fr_clean.csv\", index=False)\n",
    "print(\"‚úÖ Grippe France nettoy√© :\", grippe_fr.shape)\n",
    "\n",
    "\n",
    "# --- B. Grippe par r√©gion ---\n",
    "grippe_reg = pd.read_csv(data_path + \"grippe-passages-urgences-et-actes-sos-medecin_reg.csv\", sep=\";\", low_memory=False)\n",
    "grippe_reg = normalize_cols(grippe_reg)\n",
    "if \"date_de_passage\" in grippe_reg.columns and \"nombre_de_passages\" in grippe_reg.columns:\n",
    "    grippe_reg = to_weekly(grippe_reg, date_col=\"date_de_passage\", value_col=\"nombre_de_passages\", agg=\"sum\")\n",
    "    grippe_reg.rename(columns={\"nombre_de_passages\": \"cas_grippe_reg\"}, inplace=True)\n",
    "grippe_reg.to_csv(clean_path + \"grippe_reg_clean.csv\", index=False)\n",
    "print(\"‚úÖ Grippe R√©gion nettoy√© :\", grippe_reg.shape)\n",
    "\n",
    "\n",
    "# --- C. Couverture vaccinale France ---\n",
    "vacc_fr = pd.read_csv(data_path + \"couvertures-vaccinales-des-adolescents-et-adultes-depuis-2011-france.csv\", sep=\";\", low_memory=False)\n",
    "vacc_fr = normalize_cols(vacc_fr)\n",
    "if \"annee\" in vacc_fr.columns:\n",
    "    vacc_fr[\"date\"] = pd.to_datetime(vacc_fr[\"annee\"].astype(str) + \"-01-01\")\n",
    "    vacc_fr = vacc_fr.groupby(\"date\")[\"couverture_vaccinale_pourcent\"].mean().reset_index()\n",
    "vacc_fr.to_csv(clean_path + \"vacc_fr_clean.csv\", index=False)\n",
    "print(\"‚úÖ Vaccination France nettoy√© :\", vacc_fr.shape)\n",
    "\n",
    "\n",
    "# --- D. Couverture vaccinale R√©gion ---\n",
    "vacc_reg = pd.read_csv(data_path + \"couvertures-vaccinales-des-adolescents-et-adultes-depuis-2011-region.csv\", sep=\";\", low_memory=False)\n",
    "vacc_reg = normalize_cols(vacc_reg)\n",
    "if \"annee\" in vacc_reg.columns:\n",
    "    vacc_reg[\"date\"] = pd.to_datetime(vacc_reg[\"annee\"].astype(str) + \"-01-01\")\n",
    "    vacc_reg = vacc_reg.groupby(\"date\")[\"couverture_vaccinale_pourcent\"].mean().reset_index()\n",
    "    vacc_reg.rename(columns={\"couverture_vaccinale_pourcent\": \"couverture_vaccinale_region\"}, inplace=True)\n",
    "vacc_reg.to_csv(clean_path + \"vacc_reg_clean.csv\", index=False)\n",
    "print(\"‚úÖ Vaccination R√©gion nettoy√© :\", vacc_reg.shape)\n",
    "\n",
    "\n",
    "# --- E. Pharmacies ---\n",
    "pharma = pd.read_csv(data_path + \"santefr-lieux-vaccination-grippe-pharmacie.csv\", sep=\";\", low_memory=False)\n",
    "pharma = normalize_cols(pharma)\n",
    "if \"departement\" in pharma.columns:\n",
    "    df_pharma = pharma.groupby(\"departement\").size().reset_index(name=\"nb_pharmacies\")\n",
    "    nb_pharma_total = df_pharma[\"nb_pharmacies\"].sum()\n",
    "else:\n",
    "    nb_pharma_total = len(pharma)\n",
    "df_pharma.to_csv(clean_path + \"pharma_clean.csv\", index=False)\n",
    "print(\"‚úÖ Pharmacies nettoy√© :\", nb_pharma_total)\n",
    "\n",
    "# =============================================================\n",
    "# 4Ô∏è‚É£ FUSION DES SOURCES NETTOY√âES\n",
    "# =============================================================\n",
    "\n",
    "df = grippe_fr.merge(vacc_fr, on=\"date\", how=\"left\")\n",
    "df = df.merge(vacc_reg, on=\"date\", how=\"left\")\n",
    "\n",
    "df[\"nb_pharmacies\"] = nb_pharma_total\n",
    "df = df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "print(\"‚úÖ Donn√©es fusionn√©es :\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# =============================================================\n",
    "# 5Ô∏è‚É£ NETTOYAGE FINAL ET FEATURES\n",
    "# =============================================================\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(method=\"ffill\")\n",
    "\n",
    "df[\"year\"] = df[\"date\"].dt.year\n",
    "df[\"month\"] = df[\"date\"].dt.month\n",
    "df[\"weekofyear\"] = df[\"date\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "for lag in [1, 2, 3, 4]:\n",
    "    df[f\"cas_grippe_fr_lag{lag}\"] = df[\"cas_grippe_fr\"].shift(lag)\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(\"‚úÖ Dataset final pr√™t :\", df.shape)\n",
    "\n",
    "# =============================================================\n",
    "# 6Ô∏è‚É£ S√âPARATION TRAIN (2023) / TEST (2024)\n",
    "# =============================================================\n",
    "\n",
    "train_df = df[df[\"year\"] == 2023]\n",
    "test_df = df[df[\"year\"] == 2024]\n",
    "\n",
    "X_train = train_df.drop(columns=[\"cas_grippe_fr\", \"date\"])\n",
    "y_train = train_df[\"cas_grippe_fr\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"cas_grippe_fr\", \"date\"])\n",
    "y_test = test_df[\"cas_grippe_fr\"]\n",
    "\n",
    "print(\"üìä Jeu d'entra√Ænement :\", X_train.shape, \"| Test :\", X_test.shape)\n",
    "\n",
    "# =============================================================\n",
    "# 7Ô∏è‚É£ RANDOM FOREST ‚Äî PR√âDICTION 2024\n",
    "# =============================================================\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"‚úÖ Pr√©diction 2024 effectu√©e :\")\n",
    "print(f\"   ‚û§ MAE : {mae:.2f}\")\n",
    "print(f\"   ‚û§ R¬≤  : {r2:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(test_df[\"date\"], y_test, label=\"R√©el\", color=\"orange\")\n",
    "plt.plot(test_df[\"date\"], y_pred, label=\"Pr√©dit\", color=\"green\")\n",
    "plt.title(\"üìà Pr√©diction du nombre de cas de grippe (2024)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# 8Ô∏è‚É£ SAUVEGARDE DU DATASET NETTOY√â\n",
    "# =============================================================\n",
    "\n",
    "output_path = clean_path + \"data_clean.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"üíæ Dataset propre sauvegard√© : {output_path}\")\n",
    "\n",
    "# =============================================================\n",
    "# 9Ô∏è‚É£ ANALYSE DE CORR√âLATION ENTRE LES VARIABLES\n",
    "# =============================================================\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"üîç Analyse de corr√©lation entre les variables principales...\")\n",
    "\n",
    "# --- On s√©lectionne uniquement les colonnes num√©riques\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "corr = df[num_cols].corr()\n",
    "\n",
    "# --- Affichage du tableau de corr√©lation\n",
    "display(corr.round(2))\n",
    "\n",
    "# --- Heatmap pour visualisation globale\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"üîó Corr√©lation entre variables (plus proche de 1 ou -1 = forte corr√©lation)\")\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# üîÅ Corr√©lation d√©cal√©e dans le temps\n",
    "# =============================================================\n",
    "\n",
    "from pandas.plotting import lag_plot\n",
    "\n",
    "def cross_corr(a, b, lag=0):\n",
    "    \"\"\"Calcule la corr√©lation crois√©e entre deux s√©ries avec d√©calage.\"\"\"\n",
    "    return a.corr(b.shift(lag))\n",
    "\n",
    "corrs = []\n",
    "for lag in range(-6, 7):  # d√©calage de -6 √† +6 semaines\n",
    "    corrs.append({\n",
    "        \"lag(semaine)\": lag,\n",
    "        \"corr(vaccin_vs_grippe)\": cross_corr(df[\"couverture_vaccinale_pourcent\"], df[\"cas_grippe_fr\"], lag)\n",
    "    })\n",
    "\n",
    "corr_lags = pd.DataFrame(corrs)\n",
    "corr_lags.plot(x=\"lag(semaine)\", y=\"corr(vaccin_vs_grippe)\", kind=\"bar\", color=\"teal\", legend=False)\n",
    "plt.title(\"Corr√©lation vaccination ‚Üî cas grippe selon le d√©calage temporel\")\n",
    "plt.axhline(0, color=\"black\", linewidth=0.8)\n",
    "plt.ylabel(\"Corr√©lation\")\n",
    "plt.xlabel(\"D√©calage (semaines)\")\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# üîç Importance des variables selon le mod√®le Random Forest\n",
    "# =============================================================\n",
    "\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "importances = importances.sort_values(ascending=True).tail(15)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "importances.plot(kind=\"barh\", color=\"seagreen\")\n",
    "plt.title(\"üí° 15 Variables les plus influentes ‚Äî Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
