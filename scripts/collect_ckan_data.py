#!/usr/bin/env python3
"""
Collecte de donn√©es r√©elles via l'API CKAN
Sources gouvernementales fran√ßaises
"""

import requests
import pandas as pd
import json
import os
from datetime import datetime, timedelta
import time

class CKANDataCollector:
    def __init__(self):
        # Sites CKAN fran√ßais connus avec bonnes URLs
        self.ckan_sites = {
            'data.gouv.fr': 'https://www.data.gouv.fr/api/1',
            'opendata.paris': 'https://opendata.paris.fr/api/3/action',
            'data.grandlyon.com': 'https://data.grandlyon.com/api/3/action',
            'data.montpellier3m.fr': 'https://data.montpellier3m.fr/api/3/action'
        }
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'LUMEN-System/1.0 (Health Surveillance)',
            'Accept': 'application/json'
        })
    
    def search_datasets(self, site_url, query="grippe", limit=10):
        """Rechercher des datasets sur un site CKAN"""
        try:
            # Construire l'URL correcte selon le site
            if 'data.gouv.fr' in site_url:
                url = f"{site_url}/datasets"
                params = {'q': query, 'page_size': limit}
            else:
                url = f"{site_url}/package_search"
                params = {
                    'q': query,
                    'rows': limit,
                    'facet.field': ['organization', 'tags']
                }
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if data.get('success'):
                return data.get('result', {}).get('results', [])
            else:
                print(f"‚ùå Erreur API {site_url}: {data.get('error', 'Unknown error')}")
                return []
                
        except Exception as e:
            print(f"‚ùå Erreur connexion {site_url}: {e}")
            return []
    
    def get_dataset_details(self, site_url, dataset_id):
        """R√©cup√©rer les d√©tails d'un dataset"""
        try:
            url = f"{site_url}/action/package_show"
            params = {'id': dataset_id}
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if data.get('success'):
                return data.get('result')
            else:
                return None
                
        except Exception as e:
            print(f"‚ùå Erreur d√©tails dataset {dataset_id}: {e}")
            return None
    
    def download_resource(self, resource_url, filename):
        """T√©l√©charger une ressource"""
        try:
            response = self.session.get(resource_url, timeout=60)
            response.raise_for_status()
            
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            with open(filename, 'wb') as f:
                f.write(response.content)
            
            return True
        except Exception as e:
            print(f"‚ùå Erreur t√©l√©chargement {resource_url}: {e}")
            return False
    
    def collect_health_data(self):
        """Collecter les donn√©es de sant√©"""
        print("üè• COLLECTE DE DONN√âES DE SANT√â R√âELLES")
        print("=" * 50)
        
        health_datasets = []
        
        for site_name, site_url in self.ckan_sites.items():
            print(f"\nüîç Recherche sur {site_name}...")
            
            # Rechercher des datasets li√©s √† la sant√©
            queries = [
                "grippe",
                "sant√© publique", 
                "surveillance",
                "√©pid√©mie",
                "vaccination",
                "urgences",
                "hospitalisation"
            ]
            
            for query in queries:
                datasets = self.search_datasets(site_url, query, limit=5)
                
                for dataset in datasets:
                    dataset_id = dataset.get('id')
                    title = dataset.get('title', 'Sans titre')
                    organization = dataset.get('organization', {}).get('title', 'Inconnu')
                    
                    print(f"  üìä {title} ({organization})")
                    
                    # R√©cup√©rer les d√©tails
                    details = self.get_dataset_details(site_url, dataset_id)
                    if details:
                        resources = details.get('resources', [])
                        for resource in resources:
                            if resource.get('format', '').upper() in ['CSV', 'XLS', 'XLSX', 'JSON']:
                                resource_url = resource.get('url')
                                resource_name = resource.get('name', 'resource')
                                
                                # T√©l√©charger la ressource
                                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                filename = f"data/ckan/{site_name}_{timestamp}_{resource_name}.{resource.get('format', 'csv').lower()}"
                                
                                if self.download_resource(resource_url, filename):
                                    health_datasets.append({
                                        'site': site_name,
                                        'dataset_id': dataset_id,
                                        'title': title,
                                        'organization': organization,
                                        'resource_name': resource_name,
                                        'resource_url': resource_url,
                                        'filename': filename,
                                        'format': resource.get('format', 'CSV'),
                                        'size': resource.get('size', 0)
                                    })
                                    print(f"    ‚úÖ T√©l√©charg√©: {filename}")
                                
                                time.sleep(1)  # Respecter les limites de taux
        
        return health_datasets
    
    def collect_demographic_data(self):
        """Collecter les donn√©es d√©mographiques"""
        print("\nüë• COLLECTE DE DONN√âES D√âMOGRAPHIQUES")
        print("=" * 50)
        
        demographic_datasets = []
        
        for site_name, site_url in self.ckan_sites.items():
            print(f"\nüîç Recherche d√©mographie sur {site_name}...")
            
            queries = [
                "population",
                "d√©mographie", 
                "recensement",
                "INSEE",
                "commune",
                "d√©partement",
                "r√©gion"
            ]
            
            for query in queries:
                datasets = self.search_datasets(site_url, query, limit=3)
                
                for dataset in datasets:
                    dataset_id = dataset.get('id')
                    title = dataset.get('title', 'Sans titre')
                    
                    print(f"  üìä {title}")
                    
                    details = self.get_dataset_details(site_url, dataset_id)
                    if details:
                        resources = details.get('resources', [])
                        for resource in resources:
                            if resource.get('format', '').upper() in ['CSV', 'XLS', 'XLSX']:
                                resource_url = resource.get('url')
                                resource_name = resource.get('name', 'resource')
                                
                                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                filename = f"data/ckan/{site_name}_demo_{timestamp}_{resource_name}.{resource.get('format', 'csv').lower()}"
                                
                                if self.download_resource(resource_url, filename):
                                    demographic_datasets.append({
                                        'site': site_name,
                                        'dataset_id': dataset_id,
                                        'title': title,
                                        'filename': filename,
                                        'format': resource.get('format', 'CSV')
                                    })
                                    print(f"    ‚úÖ T√©l√©charg√©: {filename}")
                                
                                time.sleep(1)
        
        return demographic_datasets
    
    def process_health_data(self, health_datasets):
        """Traiter les donn√©es de sant√© t√©l√©charg√©es"""
        print("\nüîÑ TRAITEMENT DES DONN√âES DE SANT√â")
        print("=" * 50)
        
        processed_data = []
        
        for dataset in health_datasets:
            try:
                filename = dataset['filename']
                print(f"\nüìä Traitement: {filename}")
                
                # Lire le fichier selon son format
                if filename.endswith('.csv'):
                    df = pd.read_csv(filename, encoding='utf-8', low_memory=False)
                elif filename.endswith('.xlsx') or filename.endswith('.xls'):
                    df = pd.read_excel(filename)
                else:
                    print(f"  ‚ö†Ô∏è Format non support√©: {filename}")
                    continue
                
                print(f"  üìà {len(df)} lignes, {len(df.columns)} colonnes")
                print(f"  üìã Colonnes: {list(df.columns)[:5]}...")
                
                # Analyser le contenu pour d√©tecter les donn√©es de grippe
                grippe_keywords = ['grippe', 'syndrome', 'grippal', 'influenza', 'virus']
                relevant_columns = []
                
                for col in df.columns:
                    if any(keyword in str(col).lower() for keyword in grippe_keywords):
                        relevant_columns.append(col)
                
                if relevant_columns:
                    print(f"  üéØ Colonnes pertinentes: {relevant_columns}")
                    
                    # Extraire les donn√©es pertinentes
                    sample_data = df[relevant_columns].head(10)
                    print(f"  üìä √âchantillon:\n{sample_data}")
                    
                    processed_data.append({
                        'source': dataset['site'],
                        'title': dataset['title'],
                        'filename': filename,
                        'rows': len(df),
                        'columns': len(df.columns),
                        'relevant_columns': relevant_columns,
                        'data': df
                    })
                else:
                    print(f"  ‚ö†Ô∏è Aucune donn√©e de grippe d√©tect√©e")
                
            except Exception as e:
                print(f"  ‚ùå Erreur traitement {filename}: {e}")
        
        return processed_data
    
    def save_collection_report(self, health_datasets, demographic_datasets, processed_data):
        """Sauvegarder le rapport de collecte"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        report = {
            'timestamp': timestamp,
            'collection_date': datetime.now().isoformat(),
            'health_datasets': len(health_datasets),
            'demographic_datasets': len(demographic_datasets),
            'processed_datasets': len(processed_data),
            'health_files': [d['filename'] for d in health_datasets],
            'demographic_files': [d['filename'] for d in demographic_datasets],
            'processed_files': [d['filename'] for d in processed_data]
        }
        
        with open(f'data/ckan/collection_report_{timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìã Rapport sauvegard√©: data/ckan/collection_report_{timestamp}.json")
        return report

def main():
    """Fonction principale"""
    print("üöÄ COLLECTE DE DONN√âES R√âELLES VIA CKAN")
    print("=" * 60)
    print(f"‚è∞ D√©but: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    # Cr√©er le dossier de collecte
    os.makedirs('data/ckan', exist_ok=True)
    
    # Initialiser le collecteur
    collector = CKANDataCollector()
    
    try:
        # Collecter les donn√©es de sant√©
        health_datasets = collector.collect_health_data()
        
        # Collecter les donn√©es d√©mographiques
        demographic_datasets = collector.collect_demographic_data()
        
        # Traiter les donn√©es de sant√©
        processed_data = collector.process_health_data(health_datasets)
        
        # Sauvegarder le rapport
        report = collector.save_collection_report(health_datasets, demographic_datasets, processed_data)
        
        print(f"\nüéâ COLLECTE TERMIN√âE")
        print(f"üìä Datasets sant√©: {report['health_datasets']}")
        print(f"üë• Datasets d√©mographie: {report['demographic_datasets']}")
        print(f"üîÑ Datasets trait√©s: {report['processed_datasets']}")
        print(f"‚è∞ Fin: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
