#!/usr/bin/env python3
"""
Script pour faire des pr√©dictions avec le mod√®le entra√Æn√©
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
import json
import joblib
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Predictor:
    def __init__(self):
        self.base_dir = Path("data")
        self.features_dir = self.base_dir / "features"
        self.artifacts_dir = self.base_dir / "artifacts"
        self.predictions_dir = self.base_dir / "predictions"
        self.predictions_dir.mkdir(parents=True, exist_ok=True)
        
        # Fichiers d'entr√©e
        self.model_path = self.artifacts_dir / "rf.joblib"
        self.features_path = self.features_dir / "features.parquet"
        self.target_path = self.features_dir / "y_target.parquet"
        self.feature_list_path = self.features_dir / "feature_list.json"
        
        # Fichiers de sortie
        self.predictions_path = self.predictions_dir / "predictions.parquet"
        self.predictions_summary_path = self.predictions_dir / "predictions_summary.json"
    
    def load_model_and_data(self):
        """Charge le mod√®le et les donn√©es"""
        logger.info("üìä CHARGEMENT DU MOD√àLE ET DES DONN√âES")
        logger.info("=" * 50)
        
        try:
            # Charger le mod√®le
            if not self.model_path.exists():
                logger.error(f"‚ùå Mod√®le non trouv√©: {self.model_path}")
                return None, None, None, None
            
            model = joblib.load(self.model_path)
            logger.info(f"‚úÖ Mod√®le charg√©: {type(model).__name__}")
            
            # Charger les features
            if not self.features_path.exists():
                logger.error(f"‚ùå Features non trouv√©es: {self.features_path}")
                return None, None, None, None
            
            X = pd.read_parquet(self.features_path)
            logger.info(f"‚úÖ Features charg√©es: {X.shape}")
            
            # Charger la target (pour comparaison)
            y_df = pd.read_parquet(self.target_path)
            logger.info(f"‚úÖ Target charg√©e: {y_df.shape}")
            
            # Charger la liste des features
            feature_list = {}
            if self.feature_list_path.exists():
                with open(self.feature_list_path, 'r', encoding='utf-8') as f:
                    feature_list = json.load(f)
                logger.info(f"‚úÖ Liste des features charg√©e: {len(feature_list.get('feature_names', []))} features")
            
            return model, X, y_df, feature_list
            
        except Exception as e:
            logger.error(f"‚ùå Erreur chargement: {e}")
            return None, None, None, None
    
    def make_predictions(self, model, X, y_df):
        """Fait les pr√©dictions"""
        logger.info("üîÆ G√âN√âRATION DES PR√âDICTIONS")
        logger.info("=" * 50)
        
        try:
            # Pr√©dictions
            predictions = model.predict(X)
            
            # Cr√©er le DataFrame de pr√©dictions
            pred_df = y_df.copy()
            pred_df['prediction'] = predictions
            pred_df['prediction_date'] = pred_df['date'] + timedelta(days=7)
            pred_df['error'] = pred_df['y_target'] - pred_df['prediction']
            pred_df['abs_error'] = np.abs(pred_df['error'])
            pred_df['relative_error'] = pred_df['abs_error'] / (pred_df['y_target'] + 1e-6) * 100
            
            logger.info(f"‚úÖ Pr√©dictions g√©n√©r√©es: {len(predictions)} √©chantillons")
            logger.info(f"üìÖ P√©riode des pr√©dictions: {pred_df['date'].min()} √† {pred_df['date'].max()}")
            
            return pred_df
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©dictions: {e}")
            return None
    
    def analyze_predictions(self, pred_df):
        """Analyse les pr√©dictions"""
        logger.info("üìä ANALYSE DES PR√âDICTIONS")
        logger.info("=" * 50)
        
        try:
            # M√©triques globales
            mae = pred_df['abs_error'].mean()
            rmse = np.sqrt((pred_df['error'] ** 2).mean())
            mape = pred_df['relative_error'].mean()
            r2 = 1 - (pred_df['error'] ** 2).sum() / ((pred_df['y_target'] - pred_df['y_target'].mean()) ** 2).sum()
            
            # M√©triques par d√©partement
            dept_metrics = pred_df.groupby('department').agg({
                'abs_error': 'mean',
                'relative_error': 'mean',
                'y_target': ['mean', 'std'],
                'prediction': ['mean', 'std']
            }).round(2)
            
            # Top 10 meilleures pr√©dictions
            best_predictions = pred_df.nsmallest(10, 'abs_error')[['date', 'department', 'y_target', 'prediction', 'abs_error']]
            
            # Top 10 pires pr√©dictions
            worst_predictions = pred_df.nlargest(10, 'abs_error')[['date', 'department', 'y_target', 'prediction', 'abs_error']]
            
            analysis = {
                "global_metrics": {
                    "mae": float(mae),
                    "rmse": float(rmse),
                    "mape": float(mape),
                    "r2": float(r2),
                    "total_predictions": len(pred_df)
                },
                "department_metrics": dept_metrics.to_dict(),
                "best_predictions": best_predictions.to_dict('records'),
                "worst_predictions": worst_predictions.to_dict('records'),
                "prediction_stats": {
                    "mean_target": float(pred_df['y_target'].mean()),
                    "mean_prediction": float(pred_df['prediction'].mean()),
                    "std_target": float(pred_df['y_target'].std()),
                    "std_prediction": float(pred_df['prediction'].std())
                }
            }
            
            logger.info(f"üìä M√âTRIQUES GLOBALES:")
            logger.info(f"  - MAE: {mae:.2f}")
            logger.info(f"  - RMSE: {rmse:.2f}")
            logger.info(f"  - MAPE: {mape:.1f}%")
            logger.info(f"  - R¬≤: {r2:.3f}")
            
            return analysis
            
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse: {e}")
            return None
    
    def save_predictions(self, pred_df, analysis):
        """Sauvegarde les pr√©dictions et l'analyse"""
        logger.info("üíæ SAUVEGARDE DES PR√âDICTIONS")
        logger.info("=" * 50)
        
        try:
            # Sauvegarder les pr√©dictions
            pred_df.to_parquet(self.predictions_path, index=False)
            logger.info(f"‚úÖ Pr√©dictions sauvegard√©es: {self.predictions_path}")
            
            # Sauvegarder l'analyse
            with open(self.predictions_summary_path, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2, ensure_ascii=False)
            logger.info(f"‚úÖ Analyse sauvegard√©e: {self.predictions_summary_path}")
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde: {e}")
            return False
    
    def run_prediction(self):
        """Lance la pr√©diction compl√®te"""
        logger.info("üöÄ D√âBUT DE LA PR√âDICTION")
        logger.info("=" * 60)
        
        # Charger le mod√®le et les donn√©es
        model, X, y_df, feature_list = self.load_model_and_data()
        if model is None:
            return False
        
        # Faire les pr√©dictions
        pred_df = self.make_predictions(model, X, y_df)
        if pred_df is None:
            return False
        
        # Analyser les pr√©dictions
        analysis = self.analyze_predictions(pred_df)
        if analysis is None:
            return False
        
        # Sauvegarder
        success = self.save_predictions(pred_df, analysis)
        
        if success:
            logger.info("‚úÖ PR√âDICTION TERMIN√âE AVEC SUCC√àS")
            logger.info("=" * 60)
            logger.info(f"üéØ MAE: {analysis['global_metrics']['mae']:.2f}")
            logger.info(f"üìä R¬≤: {analysis['global_metrics']['r2']:.3f}")
            logger.info(f"üíæ Pr√©dictions sauvegard√©es: {self.predictions_path}")
            return True
        else:
            logger.error("‚ùå √âCHEC DE LA PR√âDICTION")
            return False

if __name__ == "__main__":
    predictor = Predictor()
    predictor.run_prediction()
