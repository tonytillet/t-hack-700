#!/usr/bin/env python3
"""
Collecte de donn√©es r√©elles via l'API CKAN
Utilisation correcte de l'API CKAN selon la documentation
"""

import requests
import pandas as pd
import json
import os
from datetime import datetime, timedelta
import time

class CKANRealCollector:
    def __init__(self):
        # Sites CKAN fran√ßais avec URLs correctes
        self.ckan_sites = {
            'data.gouv.fr': {
                'base_url': 'https://www.data.gouv.fr/api/1',
                'api_version': '1',
                'search_endpoint': 'datasets'
            },
            'opendata.paris': {
                'base_url': 'https://opendata.paris.fr/api/3/action',
                'api_version': '3',
                'search_endpoint': 'package_search'
            },
            'data.grandlyon.com': {
                'base_url': 'https://data.grandlyon.com/api/3/action',
                'api_version': '3',
                'search_endpoint': 'package_search'
            },
            'data.montpellier3m.fr': {
                'base_url': 'https://data.montpellier3m.fr/api/3/action',
                'api_version': '3',
                'search_endpoint': 'package_search'
            }
        }
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'LUMEN-System/1.0 (Health Surveillance)',
            'Accept': 'application/json'
        })
    
    def test_ckan_connection(self, site_name, site_config):
        """Tester la connexion √† un site CKAN"""
        try:
            if site_config['api_version'] == '1':
                # API v1 (data.gouv.fr)
                url = f"{site_config['base_url']}/datasets"
                response = self.session.get(url, timeout=10)
            else:
                # API v3 (CKAN standard)
                url = f"{site_config['base_url']}/package_list"
                response = self.session.get(url, timeout=10)
            
            if response.status_code == 200:
                print(f"‚úÖ {site_name}: Connexion OK")
                return True
            else:
                print(f"‚ùå {site_name}: Erreur {response.status_code}")
                return False
                
        except Exception as e:
            print(f"‚ùå {site_name}: {e}")
            return False
    
    def search_datasets_v1(self, site_config, query, limit=10):
        """Rechercher des datasets avec API v1 (data.gouv.fr)"""
        try:
            url = f"{site_config['base_url']}/datasets"
            params = {
                'q': query,
                'page_size': limit,
                'sort': '-created'
            }
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if 'data' in data:
                return data['data']
            else:
                return []
                
        except Exception as e:
            print(f"‚ùå Erreur recherche v1: {e}")
            return []
    
    def search_datasets_v3(self, site_config, query, limit=10):
        """Rechercher des datasets avec API v3 (CKAN standard)"""
        try:
            url = f"{site_config['base_url']}/package_search"
            params = {
                'q': query,
                'rows': limit,
                'facet.field': ['organization', 'tags']
            }
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if data.get('success'):
                return data.get('result', {}).get('results', [])
            else:
                print(f"‚ùå Erreur API: {data.get('error', 'Unknown error')}")
                return []
                
        except Exception as e:
            print(f"‚ùå Erreur recherche v3: {e}")
            return []
    
    def get_dataset_details_v1(self, site_config, dataset_id):
        """R√©cup√©rer les d√©tails d'un dataset avec API v1"""
        try:
            url = f"{site_config['base_url']}/datasets/{dataset_id}"
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            return response.json()
            
        except Exception as e:
            print(f"‚ùå Erreur d√©tails v1: {e}")
            return None
    
    def get_dataset_details_v3(self, site_config, dataset_id):
        """R√©cup√©rer les d√©tails d'un dataset avec API v3"""
        try:
            url = f"{site_config['base_url']}/package_show"
            params = {'id': dataset_id}
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if data.get('success'):
                return data.get('result')
            else:
                return None
                
        except Exception as e:
            print(f"‚ùå Erreur d√©tails v3: {e}")
            return None
    
    def download_resource(self, resource_url, filename):
        """T√©l√©charger une ressource"""
        try:
            response = self.session.get(resource_url, timeout=60)
            response.raise_for_status()
            
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            with open(filename, 'wb') as f:
                f.write(response.content)
            
            return True
        except Exception as e:
            print(f"‚ùå Erreur t√©l√©chargement {resource_url}: {e}")
            return False
    
    def collect_health_data(self):
        """Collecter les donn√©es de sant√© via CKAN"""
        print("üè• COLLECTE DE DONN√âES DE SANT√â VIA CKAN")
        print("=" * 50)
        
        health_datasets = []
        
        for site_name, site_config in self.ckan_sites.items():
            print(f"\nüîç Test connexion {site_name}...")
            
            # Tester la connexion
            if not self.test_ckan_connection(site_name, site_config):
                continue
            
            print(f"üìä Recherche sur {site_name}...")
            
            # Rechercher des datasets li√©s √† la sant√©
            queries = [
                "grippe",
                "sant√© publique", 
                "surveillance",
                "√©pid√©mie",
                "vaccination",
                "urgences",
                "hospitalisation",
                "m√©dical",
                "sant√©"
            ]
            
            for query in queries:
                print(f"  üîç Recherche: '{query}'")
                
                # Utiliser la bonne API selon la version
                if site_config['api_version'] == '1':
                    datasets = self.search_datasets_v1(site_config, query, limit=5)
                else:
                    datasets = self.search_datasets_v3(site_config, query, limit=5)
                
                print(f"    üìä {len(datasets)} datasets trouv√©s")
                
                for dataset in datasets:
                    dataset_id = dataset.get('id') or dataset.get('slug')
                    title = dataset.get('title', 'Sans titre')
                    organization = dataset.get('organization', {})
                    if isinstance(organization, dict):
                        org_name = organization.get('title', organization.get('name', 'Inconnu'))
                    else:
                        org_name = str(organization)
                    
                    print(f"    üìã {title} ({org_name})")
                    
                    # R√©cup√©rer les d√©tails
                    if site_config['api_version'] == '1':
                        details = self.get_dataset_details_v1(site_config, dataset_id)
                    else:
                        details = self.get_dataset_details_v3(site_config, dataset_id)
                    
                    if details:
                        # Traiter les ressources selon la version d'API
                        if site_config['api_version'] == '1':
                            resources = details.get('resources', [])
                        else:
                            resources = details.get('resources', [])
                        
                        for resource in resources:
                            if resource.get('format', '').upper() in ['CSV', 'XLS', 'XLSX', 'JSON', 'XML']:
                                resource_url = resource.get('url')
                                resource_name = resource.get('name', 'resource')
                                
                                # T√©l√©charger la ressource
                                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                file_ext = resource.get('format', 'csv').lower()
                                filename = f"data/ckan/{site_name}_{timestamp}_{resource_name}.{file_ext}"
                                
                                print(f"      üì• T√©l√©chargement: {resource_name}")
                                if self.download_resource(resource_url, filename):
                                    health_datasets.append({
                                        'site': site_name,
                                        'dataset_id': dataset_id,
                                        'title': title,
                                        'organization': org_name,
                                        'resource_name': resource_name,
                                        'resource_url': resource_url,
                                        'filename': filename,
                                        'format': resource.get('format', 'CSV'),
                                        'size': resource.get('size', 0)
                                    })
                                    print(f"        ‚úÖ T√©l√©charg√©: {filename}")
                                
                                time.sleep(1)  # Respecter les limites de taux
        
        return health_datasets
    
    def collect_demographic_data(self):
        """Collecter les donn√©es d√©mographiques via CKAN"""
        print("\nüë• COLLECTE DE DONN√âES D√âMOGRAPHIQUES VIA CKAN")
        print("=" * 50)
        
        demographic_datasets = []
        
        for site_name, site_config in self.ckan_sites.items():
            print(f"\nüîç Recherche d√©mographie sur {site_name}...")
            
            if not self.test_ckan_connection(site_name, site_config):
                continue
            
            queries = [
                "population",
                "d√©mographie", 
                "recensement",
                "INSEE",
                "commune",
                "d√©partement",
                "r√©gion",
                "habitants"
            ]
            
            for query in queries:
                print(f"  üîç Recherche: '{query}'")
                
                if site_config['api_version'] == '1':
                    datasets = self.search_datasets_v1(site_config, query, limit=3)
                else:
                    datasets = self.search_datasets_v3(site_config, query, limit=3)
                
                print(f"    üìä {len(datasets)} datasets trouv√©s")
                
                for dataset in datasets:
                    dataset_id = dataset.get('id') or dataset.get('slug')
                    title = dataset.get('title', 'Sans titre')
                    
                    print(f"    üìã {title}")
                    
                    if site_config['api_version'] == '1':
                        details = self.get_dataset_details_v1(site_config, dataset_id)
                    else:
                        details = self.get_dataset_details_v3(site_config, dataset_id)
                    
                    if details:
                        if site_config['api_version'] == '1':
                            resources = details.get('resources', [])
                        else:
                            resources = details.get('resources', [])
                        
                        for resource in resources:
                            if resource.get('format', '').upper() in ['CSV', 'XLS', 'XLSX']:
                                resource_url = resource.get('url')
                                resource_name = resource.get('name', 'resource')
                                
                                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                                file_ext = resource.get('format', 'csv').lower()
                                filename = f"data/ckan/{site_name}_demo_{timestamp}_{resource_name}.{file_ext}"
                                
                                print(f"      üì• T√©l√©chargement: {resource_name}")
                                if self.download_resource(resource_url, filename):
                                    demographic_datasets.append({
                                        'site': site_name,
                                        'dataset_id': dataset_id,
                                        'title': title,
                                        'filename': filename,
                                        'format': resource.get('format', 'CSV')
                                    })
                                    print(f"        ‚úÖ T√©l√©charg√©: {filename}")
                                
                                time.sleep(1)
        
        return demographic_datasets
    
    def process_downloaded_data(self, health_datasets, demographic_datasets):
        """Traiter les donn√©es t√©l√©charg√©es"""
        print("\nüîÑ TRAITEMENT DES DONN√âES T√âL√âCHARG√âES")
        print("=" * 50)
        
        processed_data = []
        
        all_datasets = health_datasets + demographic_datasets
        
        for dataset in all_datasets:
            try:
                filename = dataset['filename']
                print(f"\nüìä Traitement: {filename}")
                
                # Lire le fichier selon son format
                if filename.endswith('.csv'):
                    df = pd.read_csv(filename, encoding='utf-8', low_memory=False)
                elif filename.endswith('.xlsx') or filename.endswith('.xls'):
                    df = pd.read_excel(filename)
                elif filename.endswith('.json'):
                    with open(filename, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    df = pd.DataFrame(data) if isinstance(data, list) else pd.DataFrame([data])
                else:
                    print(f"  ‚ö†Ô∏è Format non support√©: {filename}")
                    continue
                
                print(f"  üìà {len(df)} lignes, {len(df.columns)} colonnes")
                print(f"  üìã Colonnes: {list(df.columns)[:5]}...")
                
                # Analyser le contenu
                health_keywords = ['grippe', 'syndrome', 'grippal', 'influenza', 'virus', 'sant√©', 'm√©dical']
                demo_keywords = ['population', 'habitants', 'commune', 'd√©partement', 'r√©gion']
                
                relevant_columns = []
                for col in df.columns:
                    col_lower = str(col).lower()
                    if any(keyword in col_lower for keyword in health_keywords + demo_keywords):
                        relevant_columns.append(col)
                
                if relevant_columns:
                    print(f"  üéØ Colonnes pertinentes: {relevant_columns}")
                    
                    # Extraire les donn√©es pertinentes
                    sample_data = df[relevant_columns].head(5)
                    print(f"  üìä √âchantillon:\n{sample_data}")
                    
                    processed_data.append({
                        'source': dataset['site'],
                        'title': dataset['title'],
                        'filename': filename,
                        'rows': len(df),
                        'columns': len(df.columns),
                        'relevant_columns': relevant_columns,
                        'data': df,
                        'type': 'health' if any(keyword in str(dataset.get('title', '')).lower() for keyword in health_keywords) else 'demographic'
                    })
                else:
                    print(f"  ‚ö†Ô∏è Aucune donn√©e pertinente d√©tect√©e")
                
            except Exception as e:
                print(f"  ‚ùå Erreur traitement {filename}: {e}")
        
        return processed_data
    
    def save_collection_report(self, health_datasets, demographic_datasets, processed_data):
        """Sauvegarder le rapport de collecte"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        report = {
            'timestamp': timestamp,
            'collection_date': datetime.now().isoformat(),
            'health_datasets': len(health_datasets),
            'demographic_datasets': len(demographic_datasets),
            'processed_datasets': len(processed_data),
            'health_files': [d['filename'] for d in health_datasets],
            'demographic_files': [d['filename'] for d in demographic_datasets],
            'processed_files': [d['filename'] for d in processed_data],
            'sites_accessed': list(set([d['site'] for d in health_datasets + demographic_datasets]))
        }
        
        os.makedirs('data/ckan', exist_ok=True)
        with open(f'data/ckan/collection_report_{timestamp}.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìã Rapport sauvegard√©: data/ckan/collection_report_{timestamp}.json")
        return report

def main():
    """Fonction principale"""
    print("üöÄ COLLECTE DE DONN√âES R√âELLES VIA CKAN")
    print("=" * 60)
    print(f"‚è∞ D√©but: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    # Cr√©er le dossier de collecte
    os.makedirs('data/ckan', exist_ok=True)
    
    # Initialiser le collecteur
    collector = CKANRealCollector()
    
    try:
        # Collecter les donn√©es de sant√©
        health_datasets = collector.collect_health_data()
        
        # Collecter les donn√©es d√©mographiques
        demographic_datasets = collector.collect_demographic_data()
        
        # Traiter les donn√©es t√©l√©charg√©es
        processed_data = collector.process_downloaded_data(health_datasets, demographic_datasets)
        
        # Sauvegarder le rapport
        report = collector.save_collection_report(health_datasets, demographic_datasets, processed_data)
        
        print(f"\nüéâ COLLECTE TERMIN√âE")
        print(f"üìä Datasets sant√©: {report['health_datasets']}")
        print(f"üë• Datasets d√©mographie: {report['demographic_datasets']}")
        print(f"üîÑ Datasets trait√©s: {report['processed_datasets']}")
        print(f"üåê Sites accessibles: {', '.join(report['sites_accessed'])}")
        print(f"‚è∞ Fin: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
